{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Mining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1. Data Preprocessing and Imports](#preprocessing)\n",
    "##### [1.1 Keyword extraction](#sampling)\n",
    "##### [1.1 Keyword extraction](#keywords)\n",
    "##### [2. Models](#models)\n",
    "###### [2.1. Cosine Similarity](#cosine)\n",
    "###### [2.2. LSI Model](#lsi)\n",
    "###### [2.3. Mixture Model](#mixture)\n",
    "##### [3. Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1. Data Preprocessing and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages to install in cmd upfront:\n",
    "\n",
    "conda install -c conda-forge selenium <\\br>\n",
    "conda install -c anaconda nltk <\\br>\n",
    "pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import inflect\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.metrics import jaccard_score, pairwise_distances_chunked, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions module\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "interactions_raw = pd.read_csv(\n",
    "        './Data/RAW_interactions.csv')\n",
    "recipes_raw = pd.read_csv(\n",
    "        './Data/RAW_recipes.csv', parse_dates=['submitted'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies so that we don't have to reload the data after mistakes\n",
    "interactions_data = interactions_raw.copy()\n",
    "recipes_data = recipes_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to more explanatory names\n",
    "recipes_data.rename(columns={\"id\": \"recipe_id\"}, inplace=True)\n",
    "\n",
    "# Fill nan\n",
    "# recipes_data.fillna(\"\", inplace=True)\n",
    "# interactions_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_with_NAs(recipes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sampling'></a>\n",
    "### Provisory recipe filter/sampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an age column for the recipes\n",
    "recipes_data['age'] = round((2019-recipes_data.submitted.dt.year)+recipes_data.submitted.dt.month/12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering recipes less than 15 and older than 8 years old: (21913, 15)\n",
      "Shape after filtering recipes less than 10 and younger than 8 years old: (11151, 15)\n",
      "Shape after removing 1 step recipes w/ low interactions: (11151, 15)\n",
      "Shape after removing recipes w/o ratings: (11151, 15)\n",
      "Shape after removing 0 minutes interaction w/ low interactions: (11103, 15)\n",
      "Shape after dropping duplicates: (11090, 15)\n",
      "URLs created for each of the 11090 recipes\n"
     ]
    }
   ],
   "source": [
    "recipes_data = get_avg_recipe_rating(interactions_data, recipes_data)\n",
    "filter_byinteractions(15,8,recipes_data, older=True)\n",
    "filter_byinteractions(10,8,recipes_data, older=False)\n",
    "filter_byquality(recipes_data)\n",
    "remove_duplicates(recipes_data)\n",
    "recipes_data = generate_URL(recipes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>['lean pork chops', 'flour', 'salt', 'dry must...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>25775</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['preheat oven to 350 degrees', 'place spinach...</td>\n",
       "      <td>if spinach scares you, this is one recipe that...</td>\n",
       "      <td>['frozen chopped spinach', 'egg', 'salt', 'bla...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>58224</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown the meat &amp; drain fat', 'stir in sugar ...</td>\n",
       "      <td>just the thing for a day when you're wanton so...</td>\n",
       "      <td>['ground beef', 'sugar', 'prepared yellow must...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>land of nod  cinnamon buns</td>\n",
       "      <td>22526</td>\n",
       "      <td>35</td>\n",
       "      <td>29212</td>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['before you turn in for the night , grease a ...</td>\n",
       "      <td>i have made this several times and it's dead e...</td>\n",
       "      <td>['rolls', 'brown sugar', 'instant vanilla pudd...</td>\n",
       "      <td>6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>51</td>\n",
       "      <td>4.73</td>\n",
       "      <td>https://www.food.com/recipe/land-of-nod-cinnam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>never weep  whipped cream</td>\n",
       "      <td>74805</td>\n",
       "      <td>5</td>\n",
       "      <td>87877</td>\n",
       "      <td>2003-11-01</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['whip all ingredients together until firm pea...</td>\n",
       "      <td>i don't know where i got this, but it works. t...</td>\n",
       "      <td>['whipping cream', 'vanilla instant pudding mi...</td>\n",
       "      <td>4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>https://www.food.com/recipe/never-weep-whipped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  recipe_id  minutes  \\\n",
       "15                   chicken lickin  good  pork chops      63986      500   \n",
       "36  how i got my family to eat spinach  spinach ca...      25775       50   \n",
       "43              immoral  sandwich filling  loose meat      58224       35   \n",
       "53                         land of nod  cinnamon buns      22526       35   \n",
       "67                          never weep  whipped cream      74805        5   \n",
       "\n",
       "    contributor_id  submitted  \\\n",
       "15           14664 2003-06-06   \n",
       "36           37305 2002-04-22   \n",
       "43           37183 2003-04-04   \n",
       "53           29212 2002-03-14   \n",
       "67           87877 2003-11-01   \n",
       "\n",
       "                                                 tags  \\\n",
       "15  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "36  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "43  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "53  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "67  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                       nutrition  n_steps  \\\n",
       "15        [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "36     [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "43      [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "53  [575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]        7   \n",
       "67       [276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]        4   \n",
       "\n",
       "                                                steps  \\\n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "36  ['preheat oven to 350 degrees', 'place spinach...   \n",
       "43  ['brown the meat & drain fat', 'stir in sugar ...   \n",
       "53  ['before you turn in for the night , grease a ...   \n",
       "67  ['whip all ingredients together until firm pea...   \n",
       "\n",
       "                                          description  \\\n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "36  if spinach scares you, this is one recipe that...   \n",
       "43  just the thing for a day when you're wanton so...   \n",
       "53  i have made this several times and it's dead e...   \n",
       "67  i don't know where i got this, but it works. t...   \n",
       "\n",
       "                                          ingredients  n_ingredients   age  \\\n",
       "15  ['lean pork chops', 'flour', 'salt', 'dry must...              7  16.5   \n",
       "36  ['frozen chopped spinach', 'egg', 'salt', 'bla...              8  17.3   \n",
       "43  ['ground beef', 'sugar', 'prepared yellow must...              8  16.3   \n",
       "53  ['rolls', 'brown sugar', 'instant vanilla pudd...              6  17.2   \n",
       "67  ['whipping cream', 'vanilla instant pudding mi...              4  16.9   \n",
       "\n",
       "    num_interactions  avg_rating  \\\n",
       "15                19        4.88   \n",
       "36               113        4.34   \n",
       "43                21        4.20   \n",
       "53                51        4.73   \n",
       "67                80        4.99   \n",
       "\n",
       "                                                  URL  \n",
       "15  https://www.food.com/recipe/chicken-lickin-goo...  \n",
       "36  https://www.food.com/recipe/how-i-got-my-famil...  \n",
       "43  https://www.food.com/recipe/immoral-sandwich-f...  \n",
       "53  https://www.food.com/recipe/land-of-nod-cinnam...  \n",
       "67  https://www.food.com/recipe/never-weep-whipped...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='keywords'></a>\n",
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ingredients and save as String\n",
    "for index, row in recipes_data.iterrows():\n",
    "    ingredientlist = row['ingredients']\n",
    "    ingredientlist = row['ingredients'].replace('[', '').replace(', ', '').replace(']', '').replace('and', '\\'').split(\"\\'\")\n",
    "    ingredientlist = list(filter(None, ingredientlist))\n",
    "    ingredientlistString = \"\"\n",
    "    for i in ingredientlist:\n",
    "        ingredientlistString = ingredientlistString + i\n",
    "    recipes_data.at[index, 'ingredients'] = ingredientlistString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords for free text features\n",
    "# recipes_data = get_keywords(recipes_data, \"steps\", \"steps_keywords\")\n",
    "# recipes_data = get_keywords(recipes_data, \"description\", \"description_keywords\")\n",
    "# interactions_data = get_keywords(interactions_data, \"review\", \"review_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>lean pork chopsfloursaltdry mustardgarlic powd...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>25775</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['preheat oven to 350 degrees', 'place spinach...</td>\n",
       "      <td>if spinach scares you, this is one recipe that...</td>\n",
       "      <td>frozen chopped spinacheggsaltblack pepperonion...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>58224</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown the meat &amp; drain fat', 'stir in sugar ...</td>\n",
       "      <td>just the thing for a day when you're wanton so...</td>\n",
       "      <td>ground beefsugarprepared yellow mustardbeercay...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  recipe_id  minutes  \\\n",
       "15                   chicken lickin  good  pork chops      63986      500   \n",
       "36  how i got my family to eat spinach  spinach ca...      25775       50   \n",
       "43              immoral  sandwich filling  loose meat      58224       35   \n",
       "\n",
       "    contributor_id  submitted  \\\n",
       "15           14664 2003-06-06   \n",
       "36           37305 2002-04-22   \n",
       "43           37183 2003-04-04   \n",
       "\n",
       "                                                 tags  \\\n",
       "15  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "36  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "43  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "15     [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "36  [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "43   [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "\n",
       "                                                steps  \\\n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "36  ['preheat oven to 350 degrees', 'place spinach...   \n",
       "43  ['brown the meat & drain fat', 'stir in sugar ...   \n",
       "\n",
       "                                          description  \\\n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "36  if spinach scares you, this is one recipe that...   \n",
       "43  just the thing for a day when you're wanton so...   \n",
       "\n",
       "                                          ingredients  n_ingredients   age  \\\n",
       "15  lean pork chopsfloursaltdry mustardgarlic powd...              7  16.5   \n",
       "36  frozen chopped spinacheggsaltblack pepperonion...              8  17.3   \n",
       "43  ground beefsugarprepared yellow mustardbeercay...              8  16.3   \n",
       "\n",
       "    num_interactions  avg_rating  \\\n",
       "15                19        4.88   \n",
       "36               113        4.34   \n",
       "43                21        4.20   \n",
       "\n",
       "                                                  URL  \n",
       "15  https://www.food.com/recipe/chicken-lickin-goo...  \n",
       "36  https://www.food.com/recipe/how-i-got-my-famil...  \n",
       "43  https://www.food.com/recipe/immoral-sandwich-f...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='user-interaction'></a>\n",
    "### Creating user-activity data & filtered interactions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data flow:\n",
    "\n",
    "filter_interactions_data() -(calls)-> \n",
    "    (impute_average_rating(), (create_activity_data() \n",
    "                                        -(calls)-> get_user_activity_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_average_rating(row, df_uactivity):\n",
    "    if (row['rating'] == 0):\n",
    "        imputed_rating = round(df_uactivity.loc[df_uactivity.user_id == row.user_id, 'uavg_rating'].values[0], 0)\n",
    "        return imputed_rating\n",
    "    else:\n",
    "        return row.rating\n",
    "\n",
    "def get_user_activity_df(df):\n",
    "    #Create a user activity dataframe\n",
    "    df_uactivity = df.groupby('user_id')['rating'].value_counts().unstack().fillna(0)\n",
    "    cols = list(df_uactivity)\n",
    "    df_uactivity['total_interactions'] = df_uactivity[cols].sum(axis=1)\n",
    "    df_uactivity['total_ratings'] = df_uactivity['total_interactions']-df_uactivity[0]\n",
    "    return df_uactivity\n",
    "\n",
    "def create_activity_data(interactions_df, num_interactions):\n",
    "    df_uactivity = get_user_activity_df(interactions_df[['recipe_id','user_id', 'rating']])\n",
    "    df_uactivity = df_uactivity[df_uactivity['total_interactions']>=7]\n",
    "    print(f'Shape after filtering out users with less than {num_interactions} interactions: {df_uactivity.shape}')\n",
    "    #create average user ratings as behavior\n",
    "    df_uactivity['uavg_rating'] = df_uactivity.iloc[:,1:6].apply(\n",
    "        lambda row: np.round(np.ma.average(list(range(1,6)), \n",
    "                                           weights = (row[1], row[2], row[3], row[4], row[5])),1), axis = 1)\n",
    "    \n",
    "    df_uactivity = df_uactivity.reset_index()\n",
    "    df_uactivity.columns.set_names(None, inplace = True)\n",
    "    \n",
    "    #drop users that only have only reviews but no ratings\n",
    "    df_uactivity.drop(df_uactivity[df_uactivity.total_ratings == 0].index, inplace=True, axis=0)\n",
    "    return df_uactivity\n",
    "\n",
    "def filter_interactions_data(interactions_df, recipes_data, num_interactions):\n",
    "    df_uactivity = create_activity_data(interactions_df, num_interactions)\n",
    "    # 1. Create Filter for interations with filtered df_uactivity -> Only interactions from active users remain\n",
    "    user_filter = pd.merge(df_uactivity[['user_id']], interactions_data[['recipe_id','user_id', 'rating']], how = 'left', on ='user_id')\n",
    "    # 2. Filter interactions with active recipes -> Only interactions from active users and clean recipes remain\n",
    "    interactions = pd.merge(recipes_data[['recipe_id']], user_filter[['recipe_id', 'user_id', 'rating']], on = 'recipe_id', how ='inner')\n",
    "    zero_ratings = len(interactions.loc[interactions.rating==0])\n",
    "    interactions['rating'] = interactions.apply(lambda row: impute_average_rating(row, df_uactivity), axis=1)\n",
    "    print(f'Number of imputed ratings: {zero_ratings}')\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering out users with less than 7 interactions: (17099, 8)\n",
      "Number of imputed ratings: 8169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63986</td>\n",
       "      <td>4470</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63986</td>\n",
       "      <td>28649</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63986</td>\n",
       "      <td>37471</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63986</td>\n",
       "      <td>60992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63986</td>\n",
       "      <td>75497</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  user_id  rating\n",
       "0      63986     4470     5.0\n",
       "1      63986    28649     4.0\n",
       "2      63986    37471     5.0\n",
       "3      63986    60992     5.0\n",
       "4      63986    75497     5.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = filter_interactions_data(interactions_data, recipes_data, num_interactions=7)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of 5 star rating interactions: 79.63%\n",
      "Percent of 4 star rating interactions: 15.58%\n",
      "Percent of 3 star rating interactions: 3.29%\n",
      "Percent of 2 star rating interactions: 1.03%\n",
      "Percent of 1 star rating interactions: 0.47%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's look at the distribution of ratings\n",
    "get_rating_dist(interactions.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input (df, column_names):\n",
    "    df_content = df\n",
    "    df_content['content'] = df.loc[:, (column_names)].apply(lambda texts: ' '.join(texts), axis=1)\n",
    "    df_content.drop(columns = column_names, inplace = True)\n",
    "    df_content['content']=df_content['content'].apply(lambda text: ' '.join(text.split()))\n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11090, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11090, 16)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all recipes are in interactions\n",
    "helper = pd.unique(interactions_data['recipe_id'])\n",
    "df_rfiltered = recipes_data[recipes_data.recipe_id.isin(helper)]\n",
    "print(recipes_data.shape)\n",
    "df_rfiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63986</td>\n",
       "      <td>chicken lickin good pork chops here's and old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25775</td>\n",
       "      <td>how i got my family to eat spinach spinach cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>58224</td>\n",
       "      <td>immoral sandwich filling loose meat just the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>22526</td>\n",
       "      <td>land of nod cinnamon buns i have made this sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>74805</td>\n",
       "      <td>never weep whipped cream i don't know where i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recipe_id                                            content\n",
       "15      63986  chicken lickin good pork chops here's and old ...\n",
       "36      25775  how i got my family to eat spinach spinach cas...\n",
       "43      58224  immoral sandwich filling loose meat just the t...\n",
       "53      22526  land of nod cinnamon buns i have made this sev...\n",
       "67      74805  never weep whipped cream i don't know where i ..."
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten steps data\n",
    "df_rfiltered.steps = df_rfiltered.loc[:, ('steps')].str.replace(\"\\[\", \"\").str.replace(\"'\", \"\").str.replace(\"\\]\", \"\").str.replace(\",\",\"\").copy()\n",
    "\n",
    "#create content df\n",
    "df_rfiltered = create_input(df_rfiltered[['recipe_id', 'name', 'description', 'steps']], ['name', 'description', 'steps'])\n",
    "\n",
    "df_rfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-198-42b999471e0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#now process content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontent_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_processed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rfiltered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcontent_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Data Science\\MMDS\\Web Mining\\Lab\\Project\\food\\WebMiningRecipeProject\\code\\functions.py\u001b[0m in \u001b[0;36mget_processed\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mdfnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recipe_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mnew_texts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfnew\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   6690\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m   6691\u001b[0m                       \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6692\u001b[1;33m                       sort=sort)\n\u001b[0m\u001b[0;32m   6693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6694\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    229\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[0mndims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(self, inplace)\u001b[0m\n\u001b[0;32m   5154\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inplace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5156\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5157\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5158\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5125\u001b[0m         \"\"\"\n\u001b[0;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5127\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5135\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5136\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1897\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 1899\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   1900\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3144\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3146\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3148\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now process content\n",
    "content_processed = get_processed(df_rfiltered)\n",
    "content_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Recommendations functions for Coverage & Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return top k predicted ratings in readable form \n",
    "\n",
    "# IMPORTANT: must set the dataframe for recipe_info index == recipe_id!\n",
    "def get_user_recommendations(user_id, similarity, content, interactions, recipe_info, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    info:\n",
    "        HTML dataframe with recommendation information\n",
    "    \"\"\"\n",
    "    #get top k recipe ids\n",
    "    topk_recipes, predictions, recipeurls, imageurls = get_topk_recipes(user_id, similarity, content, interactions, k)\n",
    "    info = recipe_info.loc[topk_recipes]\n",
    "    info = info[['name', 'minutes', 'submitted', 'description']]\n",
    "    info['prediction'] = predictions\n",
    "    info['recipeurl'] = recipeurls\n",
    "    info['imageurl'] = imageurls\n",
    "    for index, row in info.iterrows():\n",
    "        info.at[index, 'recipeurl'] = '<a href=\"'+ row['recipeurl'] + '\">'+row['recipeurl'] +'</a>'\n",
    "        info.at[index, 'imageurl'] = '<a href=\"'+ row['imageurl'] + '\"> Image of recipe '+str(index)+'</a>'\n",
    "    info = HTML(info.to_html(escape=False))\n",
    "    return info\n",
    "\n",
    "def get_topk_recipes(user_id, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    topk_recipes:\n",
    "        array of top k recipe ids\n",
    "    predictions:\n",
    "        array with top k predictions\n",
    "    recipeurls:\n",
    "        array with top k recipe urls\n",
    "    imageurls:\n",
    "        array with top k recipe imageurls\n",
    "    \"\"\"\n",
    "    prediction_df = get_user_preference(user_id,similarity, content, interactions)\n",
    "    #take only the not yet seen recipes\n",
    "    new_predictions = prediction_df[prediction_df['has_rated'] == False]\n",
    "    #sort predictions\n",
    "    ordered_predictions = new_predictions.sort_values(by='prediction', ascending=False)\n",
    "    #get recipe_id array\n",
    "    topk_recipes = ordered_predictions.index[:k].values\n",
    "    imageurls = []\n",
    "    recipeurls = []\n",
    "    for entry in topk_recipes:\n",
    "        recipeurls.append(\"https://www.food.com/recipe/\" + str(entry))\n",
    "        imageurls.append(get_image_source_url(entry))\n",
    "    predictions = ordered_predictions.prediction[:k].values\n",
    "    return topk_recipes, predictions, recipeurls, imageurls\n",
    "\n",
    "#return predictions for 1 user\n",
    "def get_user_preference(user_id, similarity, content, interactions_data):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    prediction_df:\n",
    "        DataFrame in with columns ['recipe_id','prediction', 'has_rated'] for 1 user\n",
    "    \"\"\"\n",
    "    #prepare similarity dataframe\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions_data.loc[interactions_data['user_id']==user_id, 'recipe_id'].values\n",
    "    #get similarities of ALL recipes w/ already rated recipes of user\n",
    "    sim_rated_all = sim.loc[rated_recipes, :]\n",
    "    #get ratings of already rated recipes\n",
    "    ratings = get_reshaped_ratings(user_id, interactions_data)\n",
    "    \n",
    "    #compute weighted similarities between all recipes and already rated recipes\n",
    "    weighted_sim = np.dot(ratings,sim_rated_all)\n",
    "    #compute normalization constant\n",
    "    norm_const = np.array(np.abs(sim_rated_all).sum(axis=0))\n",
    "    #return sorted predictions\n",
    "    pref_predictions = weighted_sim/norm_const\n",
    "    \n",
    "    flat_predictions = [item for sublist in pref_predictions for item in sublist]\n",
    "    #return df with recipe id also\n",
    "    prediction_df = pd.DataFrame(flat_predictions, index =content['recipe_id'].values, columns =['prediction'])\n",
    "    #indicate the already tried recipes\n",
    "    prediction_df['has_rated'] = prediction_df.index.isin(rated_recipes)\n",
    "    #order predictions\n",
    "    return prediction_df\n",
    "\n",
    "#arrange ratings for matrix multiplication\n",
    "def get_reshaped_ratings(user_id, interactions_data):\n",
    "    ratings = interactions_data[interactions_data['user_id']==user_id]\n",
    "    ratings.set_index('recipe_id', inplace=True)\n",
    "    ratings.index.set_names(None, inplace = True)\n",
    "    ratings.drop(columns='user_id', inplace=True)\n",
    "    ratings = ratings.transpose()\n",
    "    ratings.rename(index={'rating':user_id}, inplace=True)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "\n",
    "def make_all_recommendations(user_ids, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    --------\n",
    "    user_ids: Array\n",
    "        list of user ids\n",
    "    similarity: Array \n",
    "        similarity matrix with shape (#recipes, #recipes).\n",
    "    content: DataFrame\n",
    "        processed DataFrame with ['recipe_id', 'content'] used to fetch all recipes ids to make recommendations for \n",
    "        (=total training data)\n",
    "    interactions: DataFrame\n",
    "        preprocessed interactions DataFrame ['recipe_id', 'user_id', 'rating']     \n",
    "    k: integer\n",
    "        number of recommendations to make\n",
    "    Returns:\n",
    "    --------\n",
    "    nested_recommendations:\n",
    "        nested list of recommended recipe_ids for each user in param list\n",
    "        example:[[rid1, rid20, rid30...], [rid1, rid20, rid30...],[rid1, rid20, rid30...]]\n",
    "    \"\"\"\n",
    "    pbar = ProgressBar()\n",
    "    nested_recommendations=[]\n",
    "    for i in pbar(range(len(user_ids))):\n",
    "        recs = get_topk_recipes_lean(user_ids[i], similarity, content, interactions, k)\n",
    "        nested_recommendations.append(recs)\n",
    "    return nested_recommendations\n",
    "\n",
    "def get_topk_recipes_lean(user_id, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    topk_recipes:\n",
    "        array of top k recipe ids\n",
    "    predictions:\n",
    "        array with top k predictions\n",
    "    recipeurls:\n",
    "        array with top k recipe urls\n",
    "    imageurls:\n",
    "        array with top k recipe imageurls\n",
    "    \"\"\"\n",
    "    prediction_df = get_user_preference(user_id,similarity, content, interactions)\n",
    "    #take only the not yet seen recipes\n",
    "    new_predictions = prediction_df.loc[prediction_df['has_rated'] == False, :]\n",
    "    #sort predictions\n",
    "    ordered_predictions = new_predictions.sort_values(by='prediction', ascending=False)\n",
    "    #get recipe_id array\n",
    "    topk_recipes = ordered_predictions.index[:k].values\n",
    "    #predictions = ordered_predictions.prediction[:k].values\n",
    "    return topk_recipes\n",
    "\n",
    "# def get_user_recommendations_lean(user_id, similarity, content, interactions, recipe_info, k):\n",
    "#     \"\"\"\n",
    "#      Returns\n",
    "#     ----------\n",
    "#     info:\n",
    "#         HTML dataframe with recommendation information\n",
    "#     \"\"\"\n",
    "#     #get top k recipe ids\n",
    "#     topk_recipes, predictions = get_topk_recipes_lean(user_id, similarity, content, interactions, k)\n",
    "#     info = recipe_info.loc[topk_recipes]\n",
    "#     info = info[['name', 'minutes', 'submitted', 'description']]\n",
    "#     info['prediction'] = predictions\n",
    "#     return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://github.com/statisticianinstilettos/recmetrics/\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# input = nested_recommendations from make_all_recommendations\n",
    "def catalog_coverage(predicted, catalog, k):\n",
    "    \"\"\"\n",
    "    Computes the catalog coverage for k lists of recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    catalog: list\n",
    "        A list of all unique items in the training data\n",
    "        example: ['A', 'B', 'C', 'X', 'Y', Z]\n",
    "    k: integer\n",
    "        The number of observed recommendation lists\n",
    "        which randomly choosed in our offline setup\n",
    "    Returns\n",
    "    ----------\n",
    "    catalog_coverage:\n",
    "        The catalog coverage of the recommendations as a percent\n",
    "        rounded to 2 decimal places\n",
    "    ----------    \n",
    "    Metric Defintion:\n",
    "    Ge, M., Delgado-Battenfeld, C., & Jannach, D. (2010, September).\n",
    "    Beyond accuracy: evaluating recommender systems by coverage and serendipity.\n",
    "    In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). ACM.\n",
    "    \"\"\"\n",
    "    sampling = random.choices(predicted, k=k)\n",
    "    predicted_flattened = [p for sublist in sampling for p in sublist]\n",
    "    L_predictions = len(set(predicted_flattened))\n",
    "    catalog_coverage = round(L_predictions/(len(catalog)*1.0)*100,2)\n",
    "    return catalog_coverage\n",
    "\n",
    "def personalization(predicted):\n",
    "    \"\"\"\n",
    "    Personalization measures recommendation similarity across users.\n",
    "    A high score indicates good personalization (user's lists of recommendations are different).\n",
    "    A low score indicates poor personalization (user's lists of recommendations are very similar).\n",
    "    A model is \"personalizing\" well if the set of recommendations for each user is different.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    Returns:\n",
    "    -------\n",
    "        The personalization score for all recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_rec_matrix(predicted):\n",
    "        df = pd.DataFrame(data=predicted).reset_index().melt(\n",
    "            id_vars='index', value_name='item',\n",
    "        )\n",
    "        df = df[['index', 'item']].pivot(index='index', columns='item', values='item')\n",
    "        df = pd.notna(df)*1\n",
    "        rec_matrix = sp.csr_matrix(df.values)\n",
    "        return rec_matrix\n",
    "\n",
    "    #create matrix for recommendations\n",
    "    predicted = np.array(predicted)\n",
    "    rec_matrix_sparse = make_rec_matrix(predicted)\n",
    "\n",
    "    #calculate similarity for every user's recommendation list\n",
    "    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n",
    "\n",
    "    #get indicies for upper right triangle w/o diagonal\n",
    "    upper_right = np.triu_indices(similarity.shape[0], k=1)\n",
    "\n",
    "    #calculate average similarity\n",
    "    personalization = np.mean(similarity[upper_right])\n",
    "    return 1-personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Prediction function for RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for 1 already rated recipe based on similarities to other already rated recipes\n",
    "\n",
    "def get_one_prediction(similarity, content, interactions, user_id, recipe_id):\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions[interactions['user_id']==user_id]['recipe_id'].values\n",
    "    #get similarities of to be predicted recipe rating with already rated recipes by user x\n",
    "    sim_rated = sim.loc[sim.index==recipe_id, rated_recipes].loc[recipe_id].values\n",
    "    #get ratings of rated recipes\n",
    "    ratings = interactions[interactions['user_id']==user_id]['rating'].values\n",
    "    \n",
    "    actual = interactions.loc[(interactions.user_id==user_id) & (interactions.recipe_id==recipe_id)]['rating'].values[0]\n",
    "    prediction = np.dot(ratings, sim_rated) /np.array([np.abs(sim_rated).sum(axis=0)])\n",
    "    return actual, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array):\n",
    "    predictions_cos = []\n",
    "    actual_cos = []\n",
    "    pbar = ProgressBar()\n",
    "    \n",
    "    for i in pbar(range(num_interactions)):\n",
    "        act, pred = get_one_prediction(similarity, content, interactions, uid_array[i], rids_array[i])\n",
    "        predictions_cos.append(pred)\n",
    "        actual_cos.append(act)\n",
    "        \n",
    "    return predictions_cos, actual_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#only relevant if there is a recipe sample\n",
    "\n",
    "def get_interaction_processed(processed, interactions):\n",
    "    #fetch only interactions in the preprocessed sample\n",
    "    interactions_processed = interactions.loc[interactions.recipe_id.isin(processed.recipe_id)]\\\n",
    "                           .reset_index()\\\n",
    "                           .drop(columns=['index'])\n",
    "    print(f'Interactions before processing: {len(interactions.index)}\\nInteractions covered in sample: {len(interactions_processed.index)}')\n",
    "    return interactions_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosine'></a>\n",
    "### 2.1. Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Tfidf & SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim_matrix(processed, n_components):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    processed['content'] = processed['content'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(processed['content'])\n",
    "    #reduce dimensionality of tfidf matrix\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    tfidf_truncated = svd.fit_transform(tfidf_matrix) \n",
    "    cosine_sim = cosine_similarity(tfidf_truncated,tfidf_truncated)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 11090)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = get_cos_sim_matrix(content_processed, 10)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1 Make all recommendations for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% |###########################                                             |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4abe615f6ced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode.chained_assignment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnested_recommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_all_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-254e7cf8aaf7>\u001b[0m in \u001b[0;36mmake_all_recommendations\u001b[1;34m(user_ids, similarity, content, interactions, k)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mnested_recommendations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mrecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_topk_recipes_lean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mnested_recommendations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnested_recommendations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-254e7cf8aaf7>\u001b[0m in \u001b[0;36mget_topk_recipes_lean\u001b[1;34m(user_id, similarity, content, interactions, k)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtop\u001b[0m \u001b[0mk\u001b[0m \u001b[0mrecipe\u001b[0m \u001b[0mimageurls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mprediction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_preference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m#take only the not yet seen recipes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mnew_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_rated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-368cd565570d>\u001b[0m in \u001b[0;36mget_user_preference\u001b[1;34m(user_id, similarity, content, interactions_data)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mflat_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpref_predictions\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m#return df with recipe id also\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mprediction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recipe_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;31m#indicate the already tried recipes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mprediction_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_rated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrated_recipes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                     mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 451\u001b[1;33m                                        copy=copy)\n\u001b[0m\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# we could have a 1-dim or 2-dim list here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dtype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_values'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[1;31m# numpy will try to interpret nested lists as further dimensions, hence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m     \u001b[1;31m# making a 1D array that contains list-likes is a bit tricky:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "nested_recommendations = make_all_recommendations(interactions['user_id'].drop_duplicates().values, cosine_sim, content_processed, interactions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_coverage(nested_recommendations, content_processed.recipe_id.values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalization(nested_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.2 Make all predictions for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cos, actual_cos = make_all_predictions(len(interactions), cosine_sim, content_processed, interactions, \n",
    "                                            interactions['user_id'].values, interactions['recipe_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating'] = [item for sublist in predictions_cos for item in sublist]\n",
    "get_rating_dist(round(interactions.predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.3 Optimize n_components of tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_cos_param(n_components, similarity, content, interactions, uid_array, rids_array):\n",
    "    rmse_mix = []\n",
    "    \n",
    "    predictions, actuals = make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array)\n",
    "    rmse = mean_squared_error(predictions, actuals)**0.5\n",
    "    rmse_mix.append(rmse)\n",
    "    return rmse_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_cos_param(n_components, content, interactions, uid_array, rids_array, k):\n",
    "    rmse_cos = []\n",
    "    coverage_cos = []\n",
    "    personalization_cos =[]\n",
    "    \n",
    "    for n in n_components:\n",
    "        similarity = get_cos_sim_matrix(content, n_components)\n",
    "        \n",
    "        predictions, actuals = make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array)\n",
    "        rmse = mean_squared_error(predictions, actuals)**0.5\n",
    "        rmse_cos.append(rmse)\n",
    "        \n",
    "        nested_recommendations = make_all_recommendations(uid_array.drop_duplicates(), \n",
    "                                                          similarity, \n",
    "                                                          content, \n",
    "                                                          interactions, \n",
    "                                                          k)\n",
    "        coverage = catalog_coverage(nested_recommendations, content.recipe_id.values, k)\n",
    "        pers = personalization(nested_recommendations)\n",
    "        \n",
    "        coverage_cos.append(coverage)\n",
    "        personalization_cos.append(pers)\n",
    "           \n",
    "return rmse_cos, coverage_cos, personalization_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cos_tune, coverage_cos_tune, personalization_cos = tuning_mix_param(n_components,\n",
    "                                                                         cosine_sim,\n",
    "                                                                         content_processed,\n",
    "                                                                         interactions,\n",
    "                                                                         uid_array,\n",
    "                                                                         rids_array)\n",
    "rmse_cos_min = min(rmse_cos_tune)\n",
    "rmse_cos_min_idx = rmse_cos_tune.index(rmse_cos_min)\n",
    "n_components_min = n_components[rmse_cos_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_components, rmse_cos_tune)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for different tfidv/SVD models')\n",
    "plt.plot([n_components_min], [rmse_cos_min], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_comma_separated = [content_item.split(\" \") for content_item in content_processed[\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec \n",
    "model = Word2Vec(content_comma_separated, size=100)\n",
    "word2vector = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Calculate tfidf vector\n",
    "tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "tfidf.fit(content_comma_separated)\n",
    "\n",
    "# if a word was never seen - it must be at least as infrequent\n",
    "# as any of the known words - so the default idf is the max of \n",
    "# known idf's\n",
    "max_idf = max(tfidf.idf_)\n",
    "# Generate word2word matrix\n",
    "word2word = collections.defaultdict(\n",
    "    lambda: max_idf,\n",
    "    [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "# if a text is empty we should return a vector of zeros\n",
    "# with the same dimensionality as all the other vectors\n",
    "dim = len(w2v.items())\n",
    "# Generate tfidf matrix\n",
    "tfidf_matrix = np.array([\n",
    "    np.mean([word2vector[w] * word2word[w]\n",
    "             for w in words if w in word2vector] or\n",
    "            [np.zeros(dim)], axis=0)\n",
    "    for words in content_comma_separated\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "      <th>recipeurl</th>\n",
       "      <th>imageurl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74182</th>\n",
       "      <td>vodka fruitcake</td>\n",
       "      <td>60</td>\n",
       "      <td>2003-10-29</td>\n",
       "      <td>i found this on the web while searching for so...</td>\n",
       "      <td>4.871163</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/74182\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96582</th>\n",
       "      <td>diana s awesome oatmeal muffins</td>\n",
       "      <td>45</td>\n",
       "      <td>2004-07-29</td>\n",
       "      <td>full of the good stuff- and you get to choose ...</td>\n",
       "      <td>4.870779</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/96582\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134873</th>\n",
       "      <td>crystallized orange nuts</td>\n",
       "      <td>20</td>\n",
       "      <td>2005-08-25</td>\n",
       "      <td>this is posted for the world tour 2005 recipez...</td>\n",
       "      <td>4.870549</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/134873\">h...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16746</th>\n",
       "      <td>mom s gingersnaps</td>\n",
       "      <td>20</td>\n",
       "      <td>2002-01-05</td>\n",
       "      <td>everyone in my family loves these. dad keeps a...</td>\n",
       "      <td>4.868959</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/16746\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290760</th>\n",
       "      <td>outback steakhouse copycat bread  gluten free</td>\n",
       "      <td>125</td>\n",
       "      <td>2008-03-07</td>\n",
       "      <td>close your eyes and this is pretty much the re...</td>\n",
       "      <td>4.868277</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/290760\">h...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.set_index('recipe_id', inplace=True)\n",
    "\n",
    "get_user_recommendations(60992, similarity_matrix, content_processed, interactions, recipes_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% |#######                                                                 |\r"
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "for i in pbar(range(len(interactions))):\n",
    "    act, pred = get_one_prediction(similarity_matrix, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_cos.append(pred)\n",
    "    actual_cos.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating'] = [item for sublist in predictions_cos for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation -> =/= already rated -> Coverage\n",
    "= recommend highest predicted rating NOT seen yet\n",
    "-> new prediction for ALL recipes for 1 user\n",
    "\n",
    "\n",
    "<-> Prediction -> RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mixture'></a>\n",
    "### 2.2. Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data = recipes_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_sim_matrix(processed, lmbda, df_rfiltered):\n",
    "    cos_sim = get_cos_sim_matrix(processed)\n",
    "    df_sub = df_rfiltered[['recipe_id', 'n_steps', 'minutes', 'n_ingredients']]\n",
    "    df_processed = df_sub[df_sub['recipe_id'].isin(processed['recipe_id'])]\\\n",
    "                                                             .set_index('recipe_id')\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_processed)\n",
    "    eucl_dis = euclidean_distances(X,X)\n",
    "    eucl_sim = 1/np.exp(eucl_dis)\n",
    "    mixed_sim = np.add(cos_sim*lmbda,eucl_sim*(1-lmbda)) # assume equally weighted\n",
    "    return mixed_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 11090)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_sim = get_mix_sim_matrix(content_processed, 0.5, recipes_data)\n",
    "mixed_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make recommendations based on Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data.set_index('recipe_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "      <th>recipeurl</th>\n",
       "      <th>imageurl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52840</th>\n",
       "      <td>cocoa buttermilk cake</td>\n",
       "      <td>50</td>\n",
       "      <td>2003-01-30</td>\n",
       "      <td>i adopted this recipe 9/06.  it is incredible....</td>\n",
       "      <td>4.894781</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/52840\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24612</th>\n",
       "      <td>five flavor pound cake</td>\n",
       "      <td>110</td>\n",
       "      <td>2002-04-08</td>\n",
       "      <td>i just tried this cake for the first time at f...</td>\n",
       "      <td>4.894238</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/24612\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90203</th>\n",
       "      <td>dark chocolate cake with a raspberry filling</td>\n",
       "      <td>75</td>\n",
       "      <td>2004-04-30</td>\n",
       "      <td>this is a fudgey, brownie-like cake with a cho...</td>\n",
       "      <td>4.893381</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/90203\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113914</th>\n",
       "      <td>hershey s chocolate cake with frosting</td>\n",
       "      <td>70</td>\n",
       "      <td>2005-03-22</td>\n",
       "      <td>one night i was craving chocolate cake, but we...</td>\n",
       "      <td>4.892404</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/113914\">h...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49613</th>\n",
       "      <td>the best chocolate cake  really</td>\n",
       "      <td>75</td>\n",
       "      <td>2002-12-22</td>\n",
       "      <td>i made this cake for my little brother's 12th ...</td>\n",
       "      <td>4.891674</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/49613\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_recommendations(60992, mixed_sim, content_processed, interactions, recipes_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions based on Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_mixed = []\n",
    "actual_mixed = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "for i in range(len(interactions)):\n",
    "    act, pred = get_one_prediction(mixed_sim, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_mixed.append(pred)\n",
    "    actual_mixed.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mixed = mean_squared_error(predictions_mixed, actual_mixed)**0.5\n",
    "mae_mixed = mean_absolute_error(predictions_mixed, actual_mixed)\n",
    "print(f'RMSE: {rmse_mixed}, MAE: {mae_mixed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating_mixed'] = [item for sublist in predictions_mixed for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating_mixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize lambda parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_mix_param(lmbdas, processed, interactions_data, recipes_data):\n",
    "    rmse_mix = []\n",
    "    \n",
    "    interactions_processed = get_interaction_processed(processed, interactions_data)\n",
    "    uid_sample = interactions_processed['user_id'].values\n",
    "    rid_sample = interactions_processed['recipe_id'].values\n",
    "    \n",
    "    for lmbda in lmbdas:\n",
    "        mixed_sim = get_mix_sim_matrix(processed, lmbda, recipes_data)\n",
    "        predictions_mix, actual_mix = [], []\n",
    "        for i in range(len(interactions_processed)):\n",
    "            try:\n",
    "                act, pred = get_results_cos(processed, \n",
    "                                            interactions_processed, \n",
    "                                            recipes_data, \n",
    "                                            rid_sample[i], \n",
    "                                            uid_sample[i], \n",
    "                                            mixed_sim, \n",
    "                                            5)\n",
    "                predictions_mix.append(pred)\n",
    "                actual_mix.append(act)\n",
    "                except:\n",
    "                    next\n",
    "        rmse = mean_squared_error(predictions_mix, actual_mix)**0.5\n",
    "        rmse_mix.append(rmse)\n",
    "    return rmse_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mix_tune = tuning_mix_param(lmbdas,\n",
    "                                 processed_s, \n",
    "                                 interactions_data, \n",
    "                                 recipes_data)\n",
    "rmse_mix_min = min(rmse_mix_tune)\n",
    "rmse_mix_min_idx = rmse_mix_tune.index(rmse_mix_min)\n",
    "lmbda_min = lmbdas[rmse_mix_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lmbdas, rmse_mix_tune)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for different mixture models')\n",
    "plt.plot([lmbda_min], [rmse_mix_min], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3. Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
