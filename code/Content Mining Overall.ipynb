{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Mining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1. Data Preprocessing and Imports](#preprocessing)\n",
    "##### [2. Models](#models)\n",
    "###### [2.1. Cosine Similarity](#cosine)\n",
    "###### [2.2. LSI Model](#lsi)\n",
    "###### [2.3. Mixture Model](#mixture)\n",
    "##### [3. Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1. Data Preprocessing and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages to install in cmd upfront:\n",
    "\n",
    "conda install -c conda-forge selenium <\\br>\n",
    "conda install -c anaconda nltk <\\br>\n",
    "pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import inflect\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions module\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_data = pd.read_csv(\n",
    "        'C:/Users/d067795/OneDrive - SAP SE/Documents/Master/Semester 2/Web Mining/Project/RAW_interactions.csv')\n",
    "recipes_data = pd.read_csv(\n",
    "        'C:/Users/d067795/OneDrive - SAP SE/Documents/Master/Semester 2/Web Mining/Project/RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to more explanatory names\n",
    "recipes_data.rename(columns={\"id\": \"recipe_id\"}, inplace=True)\n",
    "interactions_data.rename(columns={\"num_interactions\": \"date\", \"avg_rating\": \"rating\"}, inplace=True)\n",
    "\n",
    "# Fill nan\n",
    "recipes_data.fillna(\"\", inplace=True)\n",
    "interactions_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ingredients and save as String\n",
    "for index, row in recipes_data.iterrows():\n",
    "    ingredientlist = row['ingredients']\n",
    "    ingredientlist = row['ingredients'].replace('[', '').replace(', ', '').replace(']', '').replace('and', '\\'').split(\"\\'\")\n",
    "    ingredientlist = list(filter(None, ingredientlist))\n",
    "    ingredientlistString = \"\"\n",
    "    for i in ingredientlist:\n",
    "        ingredientlistString = ingredientlistString + i\n",
    "    recipes_data.at[index, 'ingredients'] = ingredientlistString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords for free text features\n",
    "get_keywords(recipes_data, \"steps\", \"steps_keywords\")\n",
    "get_keywords(recipes_data, \"description\", \"description_keywords\")\n",
    "get_keywords(interactions_data, \"review\", \"review_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "#Average ratings\n",
    "num_interactions = interactions_data.groupby(\"recipe_id\")[\"date\"].count()\n",
    "\n",
    "#only consider the ratings (>0) into the mean, not the reviews w/o ratings\n",
    "mean_ratings = interactions_data[interactions_data[\"rating\"]!=0].groupby(\"recipe_id\")[\"rating\"].mean()\n",
    "\n",
    "df_rmerged = recipes_data.join(num_interactions, how=\"left\", on=\"recipe_id\").join(mean_ratings, how=\"left\", on=\"recipe_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_special(words):\n",
    "    \"\"\"Remove special signs like &*\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[-,$()#+&*]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"  \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    myStopWords = []\n",
    "    stopwords.extend(myStopWords)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert words to lowercase\"\"\"\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize_lemmatize(words):\n",
    "    words = remove_special(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    #words = stem_words(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed(data):\n",
    "    processed = pd.DataFrame(data=[],columns = ['recipe_id', 'content'])\n",
    "    new_texts = []\n",
    "\n",
    "    for i in range(0, len(sample)):\n",
    "        recipe_id = sample['recipe_id'].iloc[i]\n",
    "        words = nltk.word_tokenize(sample['content'].iloc[i])\n",
    "        text = ' '.join(normalize_lemmatize(words))\n",
    "        dfnew = pd.DataFrame([[recipe_id, text]], columns=['recipe_id', 'content'])\n",
    "        new_texts.append(text)\n",
    "        processed = processed.append(dfnew,ignore_index = True)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231637, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(231637, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper = pd.unique(interactions_data['recipe_id'])\n",
    "df_rfiltered = df_rmerged[df_rmerged.recipe_id.isin(helper)]\n",
    "print(df_rmerged.shape)\n",
    "df_rfiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input (df, column_names):\n",
    "    length = len(column_names)\n",
    "    df_content = df\n",
    "    df_content['content'] = df.loc[:, (column_names)].apply(lambda texts: ' '.join(texts), axis=1)\n",
    "    df_content.drop(columns = column_names, inplace = True)\n",
    "    df_content['content']=df_content['content'].apply(lambda text: ' '.join(text.split()))\n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137739</td>\n",
       "      <td>arriba baked winter squash mexican style autum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31490</td>\n",
       "      <td>a bit different breakfast pizza this recipe ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112140</td>\n",
       "      <td>all in the kitchen chili this modified version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59389</td>\n",
       "      <td>alouette potatoes this is a super easy, great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44061</td>\n",
       "      <td>amish tomato ketchup for canning my dh's amish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                            content\n",
       "0     137739  arriba baked winter squash mexican style autum...\n",
       "1      31490  a bit different breakfast pizza this recipe ca...\n",
       "2     112140  all in the kitchen chili this modified version...\n",
       "3      59389  alouette potatoes this is a super easy, great ...\n",
       "4      44061  amish tomato ketchup for canning my dh's amish..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten steps data\n",
    "df_rfiltered.steps = df_rfiltered.loc[:, ('steps')].str.replace(\"\\[\", \"\").str.replace(\"'\", \"\").str.replace(\"\\]\", \"\").str.replace(\",\",\"\").copy()\n",
    "\n",
    "#create content df\n",
    "df_content = create_input(df_rfiltered[['recipe_id', 'name','description', 'steps']], ['name','description', 'steps'])\n",
    "\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94947</td>\n",
       "      <td>crab filled crescent snacks found in a crescen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429010</td>\n",
       "      <td>curried bean salad serve this flavorful and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277542</td>\n",
       "      <td>delicious steak with onion marinade another i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78450</td>\n",
       "      <td>pork tenderloin with hoisin another keeper fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80012</td>\n",
       "      <td>mixed baby greens with oranges grapefruit and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                            content\n",
       "0      94947  crab filled crescent snacks found in a crescen...\n",
       "1     429010  curried bean salad serve this flavorful and re...\n",
       "2     277542  delicious steak with onion marinade another i'...\n",
       "3      78450  pork tenderloin with hoisin another keeper fro...\n",
       "4      80012  mixed baby greens with oranges grapefruit and ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_content.sample(n=1000, replace=False, random_state=42)\\\n",
    "                 .reset_index()\\\n",
    "                 .drop(columns=['index'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94947</td>\n",
       "      <td>crab fill crescent snack find crescent roll re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429010</td>\n",
       "      <td>curry bean salad serve flavorful refresh salad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277542</td>\n",
       "      <td>delicious steak onion marinade another try loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78450</td>\n",
       "      <td>pork tenderloin hoisin another keeper bonnie s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80012</td>\n",
       "      <td>mix baby green oranges grapefruit avocado love...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recipe_id                                            content\n",
       "0     94947  crab fill crescent snack find crescent roll re...\n",
       "1    429010  curry bean salad serve flavorful refresh salad...\n",
       "2    277542  delicious steak onion marinade another try loo...\n",
       "3     78450  pork tenderloin hoisin another keeper bonnie s...\n",
       "4     80012  mix baby green oranges grapefruit avocado love..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = get_processed(sample)\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some stopwords\n",
    "#new_stopwords = ['.', '\\\"', '\\'', ':', '(', ')', ',', '-', 'etc', '1', '/', '2', '3', '\\'s', '\\'\\'''','``', '!' ]\n",
    "#stop_words.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosine'></a>\n",
    "### 2.1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = get_cos_sim_matrix(processed)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88378</td>\n",
       "      <td>445577</td>\n",
       "      <td>2012-07-25</td>\n",
       "      <td>5</td>\n",
       "      <td>Very good - we all enjoyed this.  I used just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2114486</td>\n",
       "      <td>445577</td>\n",
       "      <td>2013-07-04</td>\n",
       "      <td>3</td>\n",
       "      <td>I&amp;#039;d suggest using green curry paste, rath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900992</td>\n",
       "      <td>445577</td>\n",
       "      <td>2013-10-02</td>\n",
       "      <td>3</td>\n",
       "      <td>We added an extra jalapeno pepper and used Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2503874</td>\n",
       "      <td>129377</td>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>4</td>\n",
       "      <td>set up beautifully once it was completely cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247152</td>\n",
       "      <td>310201</td>\n",
       "      <td>2009-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>This was even better than expected, especially...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    88378     445577  2012-07-25       5   \n",
       "1  2114486     445577  2013-07-04       3   \n",
       "2   900992     445577  2013-10-02       3   \n",
       "3  2503874     129377  2012-11-16       4   \n",
       "4   247152     310201  2009-05-27       5   \n",
       "\n",
       "                                              review  \n",
       "0  Very good - we all enjoyed this.  I used just ...  \n",
       "1  I&#039;d suggest using green curry paste, rath...  \n",
       "2  We added an extra jalapeno pepper and used Tha...  \n",
       "3  set up beautifully once it was completely cool...  \n",
       "4  This was even better than expected, especially...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_processed = get_interaction_processed(processed, interactions_data)\n",
    "interactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(processed, interactions, recipe, cosine_sim,k):\n",
    "    interactions_processed = get_interaction_processed(processed, interactions)\n",
    "    uid_sample = interactions_processed['user_id'].values\n",
    "    rid_sample = interactions_processed['recipe_id'].values\n",
    "\n",
    "    all_rids = interactions_processed['recipe_id'].unique()\n",
    "    pred_rids = []\n",
    "\n",
    "    for i in range(len(interactions_processed)):\n",
    "        try:\n",
    "          recipe_ids = get_recommendation_cos(processed,\n",
    "                                                interactions_processed,\n",
    "                                                rid_sample[i],\n",
    "                                                uid_sample[i],\n",
    "                                                cosine_sim,\n",
    "                                                k)\n",
    "          pred_rids += list(recipe_ids)\n",
    "        except:\n",
    "          next\n",
    "    pred_bids = np.array(list(set(pred_rids)))\n",
    "    return len(pred_bids)/len(all_rids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  88378 2114486  900992 ...  428885  169430  369363]\n",
      "[445577 445577 445577 ... 273409 273409 273409]\n",
      "   user_id  recipe_id        date  rating  \\\n",
      "0    88378     445577  2012-07-25       5   \n",
      "1  2114486     445577  2013-07-04       3   \n",
      "2   900992     445577  2013-10-02       3   \n",
      "3  2503874     129377  2012-11-16       4   \n",
      "4   247152     310201  2009-05-27       5   \n",
      "\n",
      "                                              review  \n",
      "0  Very good - we all enjoyed this.  I used just ...  \n",
      "1  I&#039;d suggest using green curry paste, rath...  \n",
      "2  We added an extra jalapeno pepper and used Tha...  \n",
      "3  set up beautifully once it was completely cool...  \n",
      "4  This was even better than expected, especially...  \n",
      "  recipe_id                                            content\n",
      "0     94947  crab fill crescent snack find crescent roll re...\n",
      "1    429010  curry bean salad serve flavorful refresh salad...\n",
      "2    277542  delicious steak onion marinade another try loo...\n",
      "3     78450  pork tenderloin hoisin another keeper bonnie s...\n",
      "4     80012  mix baby green oranges grapefruit avocado love...\n"
     ]
    }
   ],
   "source": [
    "uid_sample = interactions_processed['user_id'].values\n",
    "rid_sample = interactions_processed['recipe_id'].values\n",
    "print(uid_sample)\n",
    "print(rid_sample)\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "print(interactions_processed.head())\n",
    "print(processed.head())\n",
    "\n",
    "for i in range(len(interactions_processed)):\n",
    "    try:\n",
    "        act, pred = get_results_cos(processed,\n",
    "                                    interactions_processed,\n",
    "                                    recipes_data,\n",
    "                                    rid_sample[i],\n",
    "                                    uid_sample[i],\n",
    "                                    cosine_sim,\n",
    "                                    5)\n",
    "        predictions_cos.append(pred)\n",
    "        actual_cos.append(act)\n",
    "    except:\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0697657531912885, MAE: 0.5\n"
     ]
    }
   ],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage: 0.738\n"
     ]
    }
   ],
   "source": [
    "cov_cos = get_coverage(processed, interactions_data, recipes_data, cosine_sim, 5)\n",
    "print(f'coverage: {cov_cos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lsi'></a>\n",
    "### 2.2. LSI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mixture'></a>\n",
    "### 2.3. Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3. Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
