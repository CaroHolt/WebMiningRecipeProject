{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Mining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1. Data Preprocessing and Imports](#preprocessing)\n",
    "##### [1.1 Keyword extraction](#sampling)\n",
    "##### [1.1 Keyword extraction](#keywords)\n",
    "##### [2. Models](#models)\n",
    "###### [2.1. Cosine Similarity](#cosine)\n",
    "###### [2.2. LSI Model](#lsi)\n",
    "###### [2.3. Mixture Model](#mixture)\n",
    "##### [3. Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1. Data Preprocessing and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages to install in cmd upfront:\n",
    "\n",
    "conda install -c conda-forge selenium <\\br>\n",
    "conda install -c anaconda nltk <\\br>\n",
    "pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import inflect\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.metrics import jaccard_score, pairwise_distances_chunked, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions module\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "interactions_raw = pd.read_csv(\n",
    "        'Data/RAW_interactions.csv')\n",
    "recipes_raw = pd.read_csv(\n",
    "        'Data/RAW_recipes.csv', parse_dates=['submitted'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies so that we don't have to reload the data after mistakes\n",
    "interactions_data = interactions_raw.copy()\n",
    "recipes_data = recipes_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to more explanatory names\n",
    "recipes_data.rename(columns={\"id\": \"recipe_id\"}, inplace=True)\n",
    "\n",
    "# Fill nan\n",
    "# recipes_data.fillna(\"\", inplace=True)\n",
    "# interactions_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_NAs(df):\n",
    "    df.drop(df[df[\"name\"].isna()].index, inplace =True)\n",
    "    df[\"description\"].fillna(\"\", inplace=True)\n",
    "    df.loc[144074, \"minutes\"]= 25\n",
    "    df.drop(df[df[\"name\"]==\"how to preserve a husband\"].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_with_NAs(recipes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sampling'></a>\n",
    "### Provisory recipe filter/sampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an age column for the recipes\n",
    "recipes_data['age'] = round((2019-recipes_data.submitted.dt.year)+recipes_data.submitted.dt.month/12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ratings for each recipe\n",
    "\n",
    "def get_avg_recipe_rating(interactions_df, recipes_df):\n",
    "    #Average ratings\n",
    "    num_interactions = interactions_df.groupby(\"recipe_id\")[\"date\"].count()\n",
    "    #only consider the ratings (>0) into the mean, not the reviews w/o ratings\n",
    "    mean_ratings = round(interactions_df[interactions_df[\"rating\"]!=0].groupby(\"recipe_id\")[\"rating\"].mean(), 2)\n",
    "    #merge\n",
    "    df_rmerged = recipes_df.join(num_interactions, how=\"left\", on=\"recipe_id\").join(mean_ratings, how=\"left\", on=\"recipe_id\")\n",
    "    df_rmerged = df_rmerged.rename(columns ={\"date\":\"num_interactions\", \"rating\":\"avg_rating\"})\n",
    "    return df_rmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_byquality(df):\n",
    "    df.drop(df[(df[\"n_steps\"]==1)&(df[\"num_interactions\"]==1)].index, axis=0, inplace =True)\n",
    "    print(\"Shape after removing 1 step recipes w/ low interactions:\", df.shape)\n",
    "    df.drop(df[df[\"avg_rating\"].isna()].index, axis=0, inplace =True)\n",
    "    print(\"Shape after removing recipes w/o ratings:\", df.shape)\n",
    "    df.drop(df[(df['minutes']==0)].index, axis=0, inplace=True)\n",
    "    print('Shape after removing 0 minutes interaction w/ low interactions:', df.shape)\n",
    "\n",
    "def filter_byinteractions(num_interactions, age, df, older):\n",
    "    \"\"\"\n",
    "    older: boolean\n",
    "    \"\"\"\n",
    "    if (older==True):\n",
    "        index_remove= df[(df[\"num_interactions\"]<=num_interactions) & (df[\"age\"]>age)][\"recipe_id\"].index\n",
    "        df.drop(index_remove, axis=0, inplace=True)\n",
    "        print(f'Shape after filtering recipes less than {num_interactions} and older than {age} years old: {df.shape}')\n",
    "    else:\n",
    "        index_remove= df[(df[\"num_interactions\"]<=num_interactions) & (df[\"age\"]<=age)][\"recipe_id\"].index\n",
    "        df.drop(index_remove, axis=0, inplace=True)\n",
    "        print(f'Shape after filtering recipes less than {num_interactions} and younger than {age} years old: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best(interactions, ratings, n_dupl):\n",
    "    # number of interaction are different -> there exists a maximum\n",
    "    if((len(interactions) != len(set(interactions)))) :\n",
    "        return interactions.idxmax(axis=1)\n",
    "    else:# return the maximum rating or any of the duplicate recipes\n",
    "        return ratings.idxmax(axis=1)\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    dupl_recipes = pd.DataFrame(df[df[\"name\"].duplicated(keep=False)])\n",
    "    dupl_rgrouped= dupl_recipes.groupby('name').groups\n",
    "    \n",
    "    to_keep = []\n",
    "    \n",
    "    for name in dupl_rgrouped:\n",
    "        n_dupl = len(dupl_rgrouped[name])\n",
    "        if(n_dupl == 2):\n",
    "            index1=dupl_rgrouped[name][0]\n",
    "            index2=dupl_rgrouped[name][1]\n",
    "            \n",
    "            interactions = dupl_recipes.loc[[index1, index2], ['num_interactions']].num_interactions\n",
    "            ratings = dupl_recipes.loc[[index1, index2], ['avg_rating']].avg_rating\n",
    "            to_keep.append(choose_best(interactions, ratings, n_dupl))\n",
    "        elif (n_dupl==3):\n",
    "            index1=dupl_rgrouped[name][0]\n",
    "            index2=dupl_rgrouped[name][1]\n",
    "            index3=dupl_rgrouped[name][2]\n",
    "            \n",
    "            interactions = dupl_recipes.loc[[index1, index2, index3], ['num_interactions']].num_interactions\n",
    "            ratings = dupl_recipes.loc[[index1, index2, index3], ['avg_rating']].avg_rating\n",
    "            to_keep.append(choose_best(interactions, ratings, n_dupl))\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "            break\n",
    "            \n",
    "        df.drop(df.index.intersection(to_keep), axis=0, inplace=True)\n",
    "    print('Shape after dropping duplicates:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate URL for every recipe\n",
    "def generate_URL(df):\n",
    "    df[\"URL\"] = df.apply(lambda row: \"https://www.food.com/recipe/\"+\" \".join(row[\"name\"].split()).replace(\" \", \"-\") \n",
    "                         +\"-\"+str(row[\"recipe_id\"]), axis=1)\n",
    "    print(f'URLs created for each of the {len(df.index)} recipes')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering recipes less than 15 and older than 8 years old: (21913, 15)\n",
      "Shape after filtering recipes less than 10 and younger than 8 years old: (11151, 15)\n",
      "Shape after removing 1 step recipes w/ low interactions: (11151, 15)\n",
      "Shape after removing recipes w/o ratings: (11151, 15)\n",
      "Shape after removing 0 minutes interaction w/ low interactions: (11103, 15)\n",
      "Shape after dropping duplicates: (11090, 15)\n",
      "URLs created for each of the 11090 recipes\n"
     ]
    }
   ],
   "source": [
    "recipes_data = get_avg_recipe_rating(interactions_data, recipes_data)\n",
    "filter_byinteractions(15,8,recipes_data, older=True)\n",
    "filter_byinteractions(10,8,recipes_data, older=False)\n",
    "filter_byquality(recipes_data)\n",
    "remove_duplicates(recipes_data)\n",
    "recipes_data = generate_URL(recipes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>['lean pork chops', 'flour', 'salt', 'dry must...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>25775</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['preheat oven to 350 degrees', 'place spinach...</td>\n",
       "      <td>if spinach scares you, this is one recipe that...</td>\n",
       "      <td>['frozen chopped spinach', 'egg', 'salt', 'bla...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>58224</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown the meat &amp; drain fat', 'stir in sugar ...</td>\n",
       "      <td>just the thing for a day when you're wanton so...</td>\n",
       "      <td>['ground beef', 'sugar', 'prepared yellow must...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>land of nod  cinnamon buns</td>\n",
       "      <td>22526</td>\n",
       "      <td>35</td>\n",
       "      <td>29212</td>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['before you turn in for the night , grease a ...</td>\n",
       "      <td>i have made this several times and it's dead e...</td>\n",
       "      <td>['rolls', 'brown sugar', 'instant vanilla pudd...</td>\n",
       "      <td>6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>51</td>\n",
       "      <td>4.73</td>\n",
       "      <td>https://www.food.com/recipe/land-of-nod-cinnam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>never weep  whipped cream</td>\n",
       "      <td>74805</td>\n",
       "      <td>5</td>\n",
       "      <td>87877</td>\n",
       "      <td>2003-11-01</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['whip all ingredients together until firm pea...</td>\n",
       "      <td>i don't know where i got this, but it works. t...</td>\n",
       "      <td>['whipping cream', 'vanilla instant pudding mi...</td>\n",
       "      <td>4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>https://www.food.com/recipe/never-weep-whipped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  recipe_id  minutes  \\\n",
       "15                   chicken lickin  good  pork chops      63986      500   \n",
       "36  how i got my family to eat spinach  spinach ca...      25775       50   \n",
       "43              immoral  sandwich filling  loose meat      58224       35   \n",
       "53                         land of nod  cinnamon buns      22526       35   \n",
       "67                          never weep  whipped cream      74805        5   \n",
       "\n",
       "    contributor_id  submitted  \\\n",
       "15           14664 2003-06-06   \n",
       "36           37305 2002-04-22   \n",
       "43           37183 2003-04-04   \n",
       "53           29212 2002-03-14   \n",
       "67           87877 2003-11-01   \n",
       "\n",
       "                                                 tags  \\\n",
       "15  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "36  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "43  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "53  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "67  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                       nutrition  n_steps  \\\n",
       "15        [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "36     [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "43      [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "53  [575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]        7   \n",
       "67       [276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]        4   \n",
       "\n",
       "                                                steps  \\\n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "36  ['preheat oven to 350 degrees', 'place spinach...   \n",
       "43  ['brown the meat & drain fat', 'stir in sugar ...   \n",
       "53  ['before you turn in for the night , grease a ...   \n",
       "67  ['whip all ingredients together until firm pea...   \n",
       "\n",
       "                                          description  \\\n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "36  if spinach scares you, this is one recipe that...   \n",
       "43  just the thing for a day when you're wanton so...   \n",
       "53  i have made this several times and it's dead e...   \n",
       "67  i don't know where i got this, but it works. t...   \n",
       "\n",
       "                                          ingredients  n_ingredients   age  \\\n",
       "15  ['lean pork chops', 'flour', 'salt', 'dry must...              7  16.5   \n",
       "36  ['frozen chopped spinach', 'egg', 'salt', 'bla...              8  17.3   \n",
       "43  ['ground beef', 'sugar', 'prepared yellow must...              8  16.3   \n",
       "53  ['rolls', 'brown sugar', 'instant vanilla pudd...              6  17.2   \n",
       "67  ['whipping cream', 'vanilla instant pudding mi...              4  16.9   \n",
       "\n",
       "    num_interactions  avg_rating  \\\n",
       "15                19        4.88   \n",
       "36               113        4.34   \n",
       "43                21        4.20   \n",
       "53                51        4.73   \n",
       "67                80        4.99   \n",
       "\n",
       "                                                  URL  \n",
       "15  https://www.food.com/recipe/chicken-lickin-goo...  \n",
       "36  https://www.food.com/recipe/how-i-got-my-famil...  \n",
       "43  https://www.food.com/recipe/immoral-sandwich-f...  \n",
       "53  https://www.food.com/recipe/land-of-nod-cinnam...  \n",
       "67  https://www.food.com/recipe/never-weep-whipped...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='keywords'></a>\n",
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ingredients and save as String\n",
    "for index, row in recipes_data.iterrows():\n",
    "    ingredientlist = row['ingredients']\n",
    "    ingredientlist = row['ingredients'].replace('[', '').replace(', ', '').replace(']', '').replace('and', '\\'').split(\"\\'\")\n",
    "    ingredientlist = list(filter(None, ingredientlist))\n",
    "    ingredientlistString = \"\"\n",
    "    for i in ingredientlist:\n",
    "        ingredientlistString = ingredientlistString + i\n",
    "    recipes_data.at[index, 'ingredients'] = ingredientlistString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords for free text features\n",
    "# recipes_data = get_keywords(recipes_data, \"steps\", \"steps_keywords\")\n",
    "# recipes_data = get_keywords(recipes_data, \"description\", \"description_keywords\")\n",
    "# interactions_data = get_keywords(interactions_data, \"review\", \"review_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "      <th>steps_keywords</th>\n",
       "      <th>description_keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63986</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>lean pork chopsfloursaltdry mustardgarlic powd...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "      <td>large skilletplace browned pork chops crock po...</td>\n",
       "      <td>old newspaper clipping standby years ago enjoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25775</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>frozen chopped spinacheggsaltblack pepperonion...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "      <td>itin 350 degreesplace spinach ingredients exce...</td>\n",
       "      <td>also eats never tried ... often passed hot :) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58224</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>ground beefsugarprepared yellow mustardbeercay...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "      <td>mostly cooked awaylay slices pepper sugar must...</td>\n",
       "      <td>pile well inhibitions hot loose meat bun thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        name  minutes  \\\n",
       "recipe_id                                                               \n",
       "63986                       chicken lickin  good  pork chops      500   \n",
       "25775      how i got my family to eat spinach  spinach ca...       50   \n",
       "58224                  immoral  sandwich filling  loose meat       35   \n",
       "\n",
       "           contributor_id  submitted  \\\n",
       "recipe_id                              \n",
       "63986               14664 2003-06-06   \n",
       "25775               37305 2002-04-22   \n",
       "58224               37183 2003-04-04   \n",
       "\n",
       "                                                        tags  \\\n",
       "recipe_id                                                      \n",
       "63986      ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "25775      ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "58224      ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                           nutrition  n_steps  \\\n",
       "recipe_id                                                       \n",
       "63986         [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "25775      [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "58224       [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "\n",
       "                                                 ingredients  n_ingredients  \\\n",
       "recipe_id                                                                     \n",
       "63986      lean pork chopsfloursaltdry mustardgarlic powd...              7   \n",
       "25775      frozen chopped spinacheggsaltblack pepperonion...              8   \n",
       "58224      ground beefsugarprepared yellow mustardbeercay...              8   \n",
       "\n",
       "            age  num_interactions  avg_rating  \\\n",
       "recipe_id                                       \n",
       "63986      16.5                19        4.88   \n",
       "25775      17.3               113        4.34   \n",
       "58224      16.3                21        4.20   \n",
       "\n",
       "                                                         URL  \\\n",
       "recipe_id                                                      \n",
       "63986      https://www.food.com/recipe/chicken-lickin-goo...   \n",
       "25775      https://www.food.com/recipe/how-i-got-my-famil...   \n",
       "58224      https://www.food.com/recipe/immoral-sandwich-f...   \n",
       "\n",
       "                                              steps_keywords  \\\n",
       "recipe_id                                                      \n",
       "63986      large skilletplace browned pork chops crock po...   \n",
       "25775      itin 350 degreesplace spinach ingredients exce...   \n",
       "58224      mostly cooked awaylay slices pepper sugar must...   \n",
       "\n",
       "                                        description_keywords  \n",
       "recipe_id                                                     \n",
       "63986      old newspaper clipping standby years ago enjoy...  \n",
       "25775      also eats never tried ... often passed hot :) ...  \n",
       "58224      pile well inhibitions hot loose meat bun thing...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='user-interaction'></a>\n",
    "### Creating user-activity data & filtered interactions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_average_rating(row, df_uactivity):\n",
    "    if (row['rating'] == 0):\n",
    "        imputed_rating = round(df_uactivity.loc[df_uactivity.user_id == row.user_id, 'uavg_rating'].values[0], 0)\n",
    "        return imputed_rating\n",
    "    else:\n",
    "        return row.rating\n",
    "\n",
    "def get_user_activity_df(df):\n",
    "    #Create a user activity dataframe\n",
    "    df_uactivity = df.groupby('user_id')['rating'].value_counts().unstack().fillna(0)\n",
    "    cols = list(df_uactivity)\n",
    "    df_uactivity['total_interactions'] = df_uactivity[cols].sum(axis=1)\n",
    "    df_uactivity['total_ratings'] = df_uactivity['total_interactions']-df_uactivity[0]\n",
    "    return df_uactivity\n",
    "\n",
    "def create_activity_data(interactions_df, num_interactions):\n",
    "    df_uactivity = get_user_activity_df(interactions_df[['recipe_id','user_id', 'rating']])\n",
    "    df_uactivity = df_uactivity[df_uactivity['total_interactions']>=7]\n",
    "    print(f'Shape after filtering out users with less than {num_interactions} interactions: {df_uactivity.shape}')\n",
    "    #create average user ratings as behavior\n",
    "    df_uactivity['uavg_rating'] = df_uactivity.iloc[:,1:6].apply(\n",
    "        lambda row: np.round(np.ma.average(list(range(1,6)), \n",
    "                                           weights = (row[1], row[2], row[3], row[4], row[5])),1), axis = 1)\n",
    "    \n",
    "    df_uactivity = df_uactivity.reset_index()\n",
    "    df_uactivity.columns.set_names(None, inplace = True)\n",
    "    \n",
    "    #drop users that only have only reviews but no ratings\n",
    "    df_uactivity.drop(df_uactivity[df_uactivity.total_ratings == 0].index, inplace=True, axis=0)\n",
    "    return df_uactivity\n",
    "\n",
    "def filter_interactions_data(interactions_df, recipes_data, num_interactions):\n",
    "    df_uactivity = create_activity_data(interactions_df, num_interactions)\n",
    "    # 1. Create Filter for interations with filtered df_uactivity -> Only interactions from active users remain\n",
    "    user_filter = pd.merge(df_uactivity[['user_id']], interactions_data[['recipe_id','user_id', 'rating']], how = 'left', on ='user_id')\n",
    "    # 2. Filter interactions with active recipes -> Only interactions from active users and clean recipes remain\n",
    "    interactions = pd.merge(recipes_data[['recipe_id']], user_filter[['recipe_id', 'user_id', 'rating']], on = 'recipe_id', how ='inner')\n",
    "    zero_ratings = len(interactions.loc[interactions.rating==0])\n",
    "    interactions['rating'] = interactions.apply(lambda row: impute_average_rating(row, df_uactivity), axis=1)\n",
    "    print(f'Number of imputed ratings: {zero_ratings}')\n",
    "    return interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering out users with less than 7 interactions: (17099, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg = np.multiply(a, wgt, dtype=result_dtype).sum(axis)/scl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of imputed ratings: 8169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63986</td>\n",
       "      <td>4470</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63986</td>\n",
       "      <td>28649</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63986</td>\n",
       "      <td>37471</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63986</td>\n",
       "      <td>60992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63986</td>\n",
       "      <td>75497</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  user_id  rating\n",
       "0      63986     4470     5.0\n",
       "1      63986    28649     4.0\n",
       "2      63986    37471     5.0\n",
       "3      63986    60992     5.0\n",
       "4      63986    75497     5.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = filter_interactions_data(interactions_data, recipes_data, num_interactions=7)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_dist(df_column):\n",
    "    ratings_series=pd.Series(df_column.value_counts())\n",
    "    ratings_series.plot.bar()\n",
    "    print(f'Percent of 5 star rating interactions: {round((ratings_series.loc[5]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 4 star rating interactions: {round((ratings_series.loc[4]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 3 star rating interactions: {round((ratings_series.loc[3]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 2 star rating interactions: {round((ratings_series.loc[2]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 1 star rating interactions: {round((ratings_series.loc[1]/len(df_column)*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of 5 star rating interactions: 79.63%\n",
      "Percent of 4 star rating interactions: 15.58%\n",
      "Percent of 3 star rating interactions: 3.29%\n",
      "Percent of 2 star rating interactions: 1.03%\n",
      "Percent of 1 star rating interactions: 0.47%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's look at the distribution of ratings\n",
    "get_rating_dist(interactions.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_special(words):\n",
    "    \"\"\"Remove special signs like &*\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[-,$()#+&*]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"  \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    myStopWords = []\n",
    "    stopwords.extend(myStopWords)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert words to lowercase\"\"\"\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize_lemmatize(words):\n",
    "    words = remove_special(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    #words = stem_words(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed(data):\n",
    "    processed = pd.DataFrame(data=[],columns = ['recipe_id', 'content'])\n",
    "    new_texts = []\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        recipe_id = data['recipe_id'].iloc[i]\n",
    "        words = nltk.word_tokenize(data['content'].iloc[i])\n",
    "        text = ' '.join(normalize_lemmatize(words))\n",
    "        dfnew = pd.DataFrame([[recipe_id, text]], columns=['recipe_id', 'content'])\n",
    "        new_texts.append(text)\n",
    "        processed = processed.append(dfnew,ignore_index = True)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11090, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11090, 16)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all recipes are in interactions\n",
    "helper = pd.unique(interactions_data['recipe_id'])\n",
    "df_rfiltered = recipes_data[recipes_data.recipe_id.isin(helper)]\n",
    "print(recipes_data.shape)\n",
    "df_rfiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input (df, column_names):\n",
    "    df_content = df\n",
    "    df_content['content'] = df.loc[:, (column_names)].apply(lambda texts: ' '.join(texts), axis=1)\n",
    "    df_content.drop(columns = column_names, inplace = True)\n",
    "    df_content['content']=df_content['content'].apply(lambda text: ' '.join(text.split()))\n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63986</td>\n",
       "      <td>chicken lickin good pork chops here's and old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25775</td>\n",
       "      <td>how i got my family to eat spinach spinach cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>58224</td>\n",
       "      <td>immoral sandwich filling loose meat just the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>22526</td>\n",
       "      <td>land of nod cinnamon buns i have made this sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>74805</td>\n",
       "      <td>never weep whipped cream i don't know where i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recipe_id                                            content\n",
       "15      63986  chicken lickin good pork chops here's and old ...\n",
       "36      25775  how i got my family to eat spinach spinach cas...\n",
       "43      58224  immoral sandwich filling loose meat just the t...\n",
       "53      22526  land of nod cinnamon buns i have made this sev...\n",
       "67      74805  never weep whipped cream i don't know where i ..."
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten steps data\n",
    "df_rfiltered.steps = df_rfiltered.loc[:, ('steps')].str.replace(\"\\[\", \"\").str.replace(\"'\", \"\").str.replace(\"\\]\", \"\").str.replace(\",\",\"\").copy()\n",
    "\n",
    "#create content df\n",
    "df_rfiltered = create_input(df_rfiltered[['recipe_id', 'name', 'description', 'steps']], ['name', 'description', 'steps'])\n",
    "\n",
    "df_rfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_processed = get_processed(df_rfiltered)\n",
    "content_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94947</td>\n",
       "      <td>crab filled crescent snacks crescent roll reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429010</td>\n",
       "      <td>curried bean salad serve works nicely family t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277542</td>\n",
       "      <td>delicious steak with onion marinade took estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78450</td>\n",
       "      <td>pork tenderloin with hoisin another keeper enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80012</td>\n",
       "      <td>mixed baby greens with oranges grapefruit and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                            content\n",
       "0      94947  crab filled crescent snacks crescent roll reci...\n",
       "1     429010  curried bean salad serve works nicely family t...\n",
       "2     277542  delicious steak with onion marinade took estim...\n",
       "3      78450  pork tenderloin with hoisin another keeper enj...\n",
       "4      80012  mixed baby greens with oranges grapefruit and ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = df_content.sample(n=1000, replace=False, random_state=42)\\\n",
    "#                  .reset_index()\\\n",
    "#                  .drop(columns=['index'])\n",
    "# sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Recommendations functions & Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return top k predicted ratings in readable form \n",
    "\n",
    "# IMPORTANT: must set the dataframe for recipe_info index == recipe_id!\n",
    "def get_user_recommendations(user_id, similarity, content, interactions_data, recipe_info, k):\n",
    "    #get top k recipe ids\n",
    "    topk_recipes, predictions = get_topk_recipes(user_id, similarity, content, interactions_data, k)\n",
    "    info = recipe_info.loc[topk_recipes]\n",
    "    info['prediction'] = predictions\n",
    "    return info\n",
    "\n",
    "def get_topk_recipes(user_id, similarity, content, interactions, k):\n",
    "    prediction_df = get_user_preference(user_id,similarity, content, interactions)\n",
    "    #take only the not yet seen recipes\n",
    "    new_predictions = prediction_df[prediction_df['has_rated'] == False]\n",
    "    #sort predictions\n",
    "    ordered_predictions = new_predictions.sort_values(by='prediction', ascending=False)\n",
    "    #get recipe_id array\n",
    "    topk_recipes = ordered_predictions.index[:k].values\n",
    "    predictions = ordered_predictions.prediction[:k].values\n",
    "    return topk_recipes, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return predictions for 1 user\n",
    "def get_user_preference(user_id, similarity, content, interactions_data):\n",
    "    #prepare similarity dataframe\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions_data[interactions_data['user_id']==user_id]['recipe_id'].values\n",
    "    #get similarities of ALL recipes w/ already rated recipes of user\n",
    "    sim_rated_all = sim.loc[rated_recipes, :]\n",
    "    #get ratings of already rated recipes\n",
    "    ratings = get_reshaped_ratings(user_id, interactions_data)\n",
    "    #compute weighted similarities between all recipes and already rated recipes\n",
    "    weighted_sim = np.dot(ratings,sim_rated_all)\n",
    "    #compute normalization constant\n",
    "    norm_const = np.array(np.abs(sim_rated_all).sum(axis=0))\n",
    "    #return sorted predictions\n",
    "    pref_predictions = weighted_sim/norm_const\n",
    "    flat_predictions = [item for sublist in pref_predictions for item in sublist]\n",
    "    #return df with recipe id also\n",
    "    prediction_df = pd.DataFrame(flat_predictions, index =content['recipe_id'].values, columns =['prediction'])\n",
    "    #indicate the already tried recipes\n",
    "    prediction_df['has_rated'] = prediction_df.index.isin(rated_recipes)\n",
    "    #order predictions\n",
    "    return prediction_df\n",
    "\n",
    "#arrange ratings for matrix multiplication\n",
    "def get_reshaped_ratings(user_id, interactions_data):\n",
    "    ratings = interactions_data[interactions_data['user_id']==user_id]\n",
    "    ratings.set_index('recipe_id', inplace=True)\n",
    "    ratings.index.set_names(None, inplace = True)\n",
    "    ratings.drop(columns='user_id', inplace=True)\n",
    "    ratings = ratings.transpose()\n",
    "    ratings.rename(index={'rating':user_id}, inplace=True)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://github.com/statisticianinstilettos/recmetrics/\n",
    "\n",
    "# input = nested_recommendations from make_all_recommendations\n",
    "def catalog_coverage(predicted, catalog, k):\n",
    "    \"\"\"\n",
    "    Computes the catalog coverage for k lists of recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    catalog: list\n",
    "        A list of all unique items in the training data\n",
    "        example: ['A', 'B', 'C', 'X', 'Y', Z]\n",
    "    k: integer\n",
    "        The number of observed recommendation lists\n",
    "        which randomly choosed in our offline setup\n",
    "    Returns\n",
    "    ----------\n",
    "    catalog_coverage:\n",
    "        The catalog coverage of the recommendations as a percent\n",
    "        rounded to 2 decimal places\n",
    "    ----------    \n",
    "    Metric Defintion:\n",
    "    Ge, M., Delgado-Battenfeld, C., & Jannach, D. (2010, September).\n",
    "    Beyond accuracy: evaluating recommender systems by coverage and serendipity.\n",
    "    In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). ACM.\n",
    "    \"\"\"\n",
    "    sampling = random.choices(predicted, k=k)\n",
    "    predicted_flattened = [p for sublist in sampling for p in sublist]\n",
    "    L_predictions = len(set(predicted_flattened))\n",
    "    catalog_coverage = round(L_predictions/(len(catalog)*1.0)*100,2)\n",
    "    return catalog_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def make_all_recommendations(user_ids, k):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    user_ids = list of user ids\n",
    "    k= number of recommendations\n",
    "    ... to be continued\n",
    "    \n",
    "    Returns:\n",
    "    nested_recommendations = nested list of recommended recipe_ids for each user in param list\n",
    "    example:[[rid1, rid20, rid30...], [rid1, rid20, rid30...],[rid1, rid20, rid30...]]\n",
    "    \"\"\"\n",
    "    return nested_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Prediction function for RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for 1 already rated recipe based on similarities to other already rated recipes\n",
    "\n",
    "def get_one_prediction(similarity, content, interactions, user_id, recipe_id):\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions[interactions['user_id']==user_id]['recipe_id'].values\n",
    "    #get similarities of to be predicted recipe rating with already rated recipes by user x\n",
    "    sim_rated = sim.loc[sim.index==recipe_id, rated_recipes].loc[recipe_id].values\n",
    "    #get ratings of rated recipes\n",
    "    ratings = interactions[interactions['user_id']==user_id]['rating'].values\n",
    "    \n",
    "    actual = interactions.loc[(interactions.user_id==user_id) & (interactions.recipe_id==recipe_id)]['rating'].values[0]\n",
    "    prediction = np.dot(ratings, sim_rated) /np.array([np.abs(sim_rated).sum(axis=0)])\n",
    "    return actual, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#only relevant if there is a recipe sample\n",
    "\n",
    "def get_interaction_processed(processed, interactions):\n",
    "    #fetch only interactions in the preprocessed sample\n",
    "    interactions_processed = interactions.loc[interactions.recipe_id.isin(processed.recipe_id)]\\\n",
    "                           .reset_index()\\\n",
    "                           .drop(columns=['index'])\n",
    "    print(f'Interactions before processing: {len(interactions.index)}\\nInteractions covered in sample: {len(interactions_processed.index)}')\n",
    "    return interactions_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosine'></a>\n",
    "### 2.1. Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Tfidf & SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim_matrix(processed):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    processed['content'] = processed['content'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(processed['content'])\n",
    "    #reduce dimensionality of tfidf matrix\n",
    "    svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "    tfidf_truncated = svd.fit_transform(tfidf_matrix) \n",
    "    cosine_sim = cosine_similarity(tfidf_truncated,tfidf_truncated)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 11090)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = get_cos_sim_matrix(content_processed)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1 Make all recommendations for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data.set_index('recipe_id', inplace=True)\n",
    "\n",
    "get_user_recommendations(60992, cosine_sim, processed, interactions, recipes_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.2 Make all predictions for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-37f7d4372f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_one_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpredictions_cos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mactual_cos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_sim' is not defined"
     ]
    }
   ],
   "source": [
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "\n",
    "for i in range(len(interactions)):\n",
    "    act, pred = get_one_prediction(cosine_sim, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_cos.append(pred)\n",
    "    actual_cos.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7974036648021893, MAE: 0.48986660107129026\n"
     ]
    }
   ],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interactions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-80a715bd784c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minteractions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predicted_rating'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions_cos\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minteractions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'interactions' is not defined"
     ]
    }
   ],
   "source": [
    "interactions['predicted_rating'] = [item for sublist in predictions_cos for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_rating_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-07c497afae74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_rating_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minteractions_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted_rating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_rating_dist' is not defined"
     ]
    }
   ],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11090\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec \n",
    "from gensim.similarities import MatrixSimilarity \n",
    "from gensim.matutils import Dense2Corpus\n",
    "\n",
    "# Create processed vector (TODO: Rewrite Code)\n",
    "processed_embedding = []\n",
    "for row in content_processed['content']: \n",
    "    processed_embedding.append(row)\n",
    "\n",
    "# Initialize Word2Vec Model\n",
    "model = Word2Vec(size = content_processed['content'].size)\n",
    "model.build_vocab(processed_embedding)\n",
    "\n",
    "# Train with the corpus\n",
    "model.train(processed_embedding, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n",
    "\n",
    "# Generate Similarity Matrix\n",
    "embeddings_matrix = MatrixSimilarity(Dense2Corpus(model.wv.syn0.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "\n",
    "for i in range(len(interactions)):\n",
    "    act, pred = get_one_prediction(embeddings_matrix, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_cos.append(pred)\n",
    "    actual_cos.append(act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation -> =/= already rated -> Coverage\n",
    "= recommend highest predicted rating NOT seen yet\n",
    "-> new prediction for ALL recipes for 1 user\n",
    "\n",
    "\n",
    "<-> Prediction -> RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mixture'></a>\n",
    "### 2.2. Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_sim_matrix(processed, lmbda, df_rfiltered):\n",
    "    cos_sim = get_cos_sim_matrix(processed)\n",
    "    df_sub = df_rfiltered[['recipe_id', 'n_steps', 'minutes', 'n_ingredients']]\n",
    "    df_processed = df_sub[df_sub['recipe_id'].isin(processed['recipe_id'])]\\\n",
    "                                                             .set_index('recipe_id')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_processed)\n",
    "    eucl_dis = euclidean_distances(X,X)\n",
    "    \n",
    "    eucl_sim = 1/np.exp(eucl_dis)\n",
    "    mixed_sim = np.add(cos_sim*lmbda,eucl_sim*(1-lmbda)) # assume equally weighted\n",
    "    \n",
    "    return mixed_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make recommendations based on Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions based on Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_sim = get_mix_sim_matrix(content_processed, 0.5, df_rfiltered)\n",
    "mixed_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_mixed = []\n",
    "actual_mixed = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "for i in range(len(interactions)):\n",
    "    act, pred = get_one_prediction(mixed_sim, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_mixed.append(pred)\n",
    "    actual_mixed.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mixed = mean_squared_error(predictions_mixed, actual_mixed)**0.5\n",
    "mae_mixed = mean_absolute_error(predictions_mixed, actual_mixed)\n",
    "print(f'RMSE: {rmse_mixed}, MAE: {mae_mixed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating_mixed'] = [item for sublist in predictions_mixed for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating_mixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3. Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
