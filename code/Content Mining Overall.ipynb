{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Mining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1. Data Preprocessing and Imports](#preprocessing)\n",
    "##### [2. Models](#models)\n",
    "###### [2.1. Cosine Similarity](#cosine)\n",
    "###### [2.2. LSI Model](#lsi)\n",
    "###### [2.3. Mixture Model](#mixture)\n",
    "##### [3. Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1. Data Preprocessing and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages to install in cmd upfront:\n",
    "\n",
    "conda install -c conda-forge selenium <\\br>\n",
    "conda install -c anaconda nltk <\\br>\n",
    "pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions module\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_data = pd.read_csv(\n",
    "        'Data/RAW_interactions.csv')\n",
    "recipes_data = pd.read_csv(\n",
    "        'Data/RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to more explanatory names\n",
    "recipes_data.rename(columns={\"id\": \"recipe_id\"}, inplace=True)\n",
    "interactions_data.rename(columns={\"num_interactions\": \"date\", \"avg_rating\": \"rating\"}, inplace=True)\n",
    "\n",
    "# Fill nan\n",
    "recipes_data.fillna(\"\", inplace=True)\n",
    "interactions_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ingredients and save as String\n",
    "for index, row in recipes_data.iterrows():\n",
    "    ingredientlist = row['ingredients']\n",
    "    ingredientlist = row['ingredients'].replace('[', '').replace(', ', '').replace(']', '').replace('and', '\\'').split(\"\\'\")\n",
    "    ingredientlist = list(filter(None, ingredientlist))\n",
    "    ingredientlistString = \"\"\n",
    "    for i in ingredientlist:\n",
    "        ingredientlistString = ingredientlistString + i\n",
    "    recipes_data.at[index, 'ingredients'] = ingredientlistString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2e3b5519b3cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract keywords for free text features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipes_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"steps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"steps_keywords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipes_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"description\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"description_keywords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minteractions_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"review\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"review_keywords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Data Science\\MMDS\\Web Mining\\Lab\\Project\\food\\WebMiningRecipeProject\\code\\functions.py\u001b[0m in \u001b[0;36mget_keywords\u001b[1;34m(df, oldColumnName, newColumnName)\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mall_entries\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0moldEntries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_keywords_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moldEntries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mkey_words_dict_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_word_degrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\rake_nltk\\rake.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, stopwords, punctuations, language, ranking_metric, max_length, min_length)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# If punctuations are not provided we ignore all punctuation symbols.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     23\u001b[0m         return [\n\u001b[0;32m     24\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         ]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \"\"\"\n\u001b[1;32m-> 1175\u001b[1;33m         \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;31m# If linebuffer is not empty, then include it in the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1450\u001b[0m         \u001b[1;31m# Read the requested number of bytes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             \u001b[0mnew_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m             \u001b[0mnew_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract keywords for free text features\n",
    "get_keywords(recipes_data, \"steps\", \"steps_keywords\")\n",
    "get_keywords(recipes_data, \"description\", \"description_keywords\")\n",
    "get_keywords(interactions_data, \"review\", \"review_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>steps_keywords</th>\n",
       "      <th>description_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>winter squashmexican seasoningmixed spicehoney...</td>\n",
       "      <td>7</td>\n",
       "      <td>[squash, cut, salt, depending, bakingif, desir...</td>\n",
       "      <td>[inspired, seasoning, mix, recipes, choice, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>prepared pizza crustsausage pattyeggsmilksalt ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[frothyspoon, sausage, p, bowl, cheeses, 5, mi...</td>\n",
       "      <td>[recipe, calls, prebaked, warms, well, crust, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>ground beefyellow onionsdiced tomatoestomato p...</td>\n",
       "      <td>13</td>\n",
       "      <td>[almost, brown, sautee, wiltedadd, 2, 6, chili...</td>\n",
       "      <td>[extra, large, pot, cold, rainy, day, mom, lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>spreadable cheese with garlic  herbsnew potato...</td>\n",
       "      <td>11</td>\n",
       "      <td>[buttered, 8x8, inch, glass, baking, dish, pla...</td>\n",
       "      <td>[lot, everything, reflect, great, tasting, act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>44061</td>\n",
       "      <td>190</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>tomato juiceapple cider vinegarsugarsaltpepper...</td>\n",
       "      <td>8</td>\n",
       "      <td>[entire, life, mix, necessary, amish, mother, ...</td>\n",
       "      <td>[acquire, also, prefer, taste, dh, store, much...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  recipe_id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style     137739       55   \n",
       "1            a bit different  breakfast pizza      31490       30   \n",
       "2                   all in the kitchen  chili     112140      130   \n",
       "3                          alouette  potatoes      59389       45   \n",
       "4          amish  tomato ketchup  for canning      44061      190   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "3           68585  2003-04-14   \n",
       "4           41706  2002-10-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
       "\n",
       "                                         ingredients  n_ingredients  \\\n",
       "0  winter squashmexican seasoningmixed spicehoney...              7   \n",
       "1  prepared pizza crustsausage pattyeggsmilksalt ...              6   \n",
       "2  ground beefyellow onionsdiced tomatoestomato p...             13   \n",
       "3  spreadable cheese with garlic  herbsnew potato...             11   \n",
       "4  tomato juiceapple cider vinegarsugarsaltpepper...              8   \n",
       "\n",
       "                                      steps_keywords  \\\n",
       "0  [squash, cut, salt, depending, bakingif, desir...   \n",
       "1  [frothyspoon, sausage, p, bowl, cheeses, 5, mi...   \n",
       "2  [almost, brown, sautee, wiltedadd, 2, 6, chili...   \n",
       "3  [buttered, 8x8, inch, glass, baking, dish, pla...   \n",
       "4  [entire, life, mix, necessary, amish, mother, ...   \n",
       "\n",
       "                                description_keywords  \n",
       "0  [inspired, seasoning, mix, recipes, choice, sw...  \n",
       "1  [recipe, calls, prebaked, warms, well, crust, ...  \n",
       "2  [extra, large, pot, cold, rainy, day, mom, lef...  \n",
       "3  [lot, everything, reflect, great, tasting, act...  \n",
       "4  [acquire, also, prefer, taste, dh, store, much...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "#Average ratings\n",
    "num_interactions = interactions_data.groupby(\"recipe_id\")[\"date\"].count()\n",
    "\n",
    "#only consider the ratings (>0) into the mean, not the reviews w/o ratings\n",
    "mean_ratings = interactions_data[interactions_data[\"rating\"]!=0].groupby(\"recipe_id\")[\"rating\"].mean()\n",
    "\n",
    "df_rmerged = recipes_data.join(num_interactions, how=\"left\", on=\"recipe_id\").join(mean_ratings, how=\"left\", on=\"recipe_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import the libraries\n",
    "import nltk\n",
    "import inflect\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_special(words):\n",
    "    \"\"\"Remove special signs like &*\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[-,$()#+&*]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"  \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    myStopWords = []\n",
    "    stopwords.extend(myStopWords)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert words to lowercase\"\"\"\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize_lemmatize(words):\n",
    "    words = remove_special(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    #words = stem_words(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed(data):\n",
    "    processed = pd.DataFrame(data=[],columns = ['recipe_id', 'content'])\n",
    "    new_texts = []\n",
    "\n",
    "    for i in range(0, len(sample)):\n",
    "        recipe_id = sample['recipe_id'].iloc[i]\n",
    "        words = nltk.word_tokenize(sample['content'].iloc[i])\n",
    "        text = ' '.join(normalize_lemmatize(words))\n",
    "        dfnew = pd.DataFrame([[recipe_id, text]], columns=['recipe_id', 'content'])\n",
    "        new_texts.append(text)\n",
    "        processed = processed.append(dfnew,ignore_index = True)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231637, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(231637, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper = pd.unique(interactions_data['recipe_id'])\n",
    "df_rfiltered = df_rmerged[df_rmerged.recipe_id.isin(helper)]\n",
    "print(df_rmerged.shape)\n",
    "df_rfiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input (df, column_names):\n",
    "    length = len(column_names)\n",
    "    df_content = df\n",
    "    df_content['content'] = df.loc[:, (column_names)].apply(lambda texts: ' '.join(texts), axis=1)\n",
    "    df_content.drop(columns = column_names, inplace = True)\n",
    "    df_content['content']=df_content['content'].apply(lambda text: ' '.join(text.split()))\n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\Andi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137739</td>\n",
       "      <td>arriba baked winter squash mexican style autum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31490</td>\n",
       "      <td>a bit different breakfast pizza this recipe ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112140</td>\n",
       "      <td>all in the kitchen chili this modified version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59389</td>\n",
       "      <td>alouette potatoes this is a super easy, great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44061</td>\n",
       "      <td>amish tomato ketchup for canning my dh's amish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                            content\n",
       "0     137739  arriba baked winter squash mexican style autum...\n",
       "1      31490  a bit different breakfast pizza this recipe ca...\n",
       "2     112140  all in the kitchen chili this modified version...\n",
       "3      59389  alouette potatoes this is a super easy, great ...\n",
       "4      44061  amish tomato ketchup for canning my dh's amish..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten steps data\n",
    "df_rfiltered.steps = df_rfiltered.loc[:, ('steps')].str.replace(\"\\[\", \"\").str.replace(\"'\", \"\").str.replace(\"\\]\", \"\").str.replace(\",\",\"\").copy()\n",
    "\n",
    "#create content df\n",
    "df_content = create_input(df_rfiltered[['recipe_id', 'name','description', 'steps']], ['name','description', 'steps'])\n",
    "\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94947</td>\n",
       "      <td>crab filled crescent snacks found in a crescen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429010</td>\n",
       "      <td>curried bean salad serve this flavorful and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277542</td>\n",
       "      <td>delicious steak with onion marinade another i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78450</td>\n",
       "      <td>pork tenderloin with hoisin another keeper fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80012</td>\n",
       "      <td>mixed baby greens with oranges grapefruit and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                            content\n",
       "0      94947  crab filled crescent snacks found in a crescen...\n",
       "1     429010  curried bean salad serve this flavorful and re...\n",
       "2     277542  delicious steak with onion marinade another i'...\n",
       "3      78450  pork tenderloin with hoisin another keeper fro...\n",
       "4      80012  mixed baby greens with oranges grapefruit and ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_content.sample(n=1000, replace=False, random_state=42)\\\n",
    "                 .reset_index()\\\n",
    "                 .drop(columns=['index'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94947</td>\n",
       "      <td>crab fill crescent snack find crescent roll re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429010</td>\n",
       "      <td>curry bean salad serve flavorful refresh salad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277542</td>\n",
       "      <td>delicious steak onion marinade another try loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78450</td>\n",
       "      <td>pork tenderloin hoisin another keeper bonnie s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80012</td>\n",
       "      <td>mix baby green oranges grapefruit avocado love...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recipe_id                                            content\n",
       "0     94947  crab fill crescent snack find crescent roll re...\n",
       "1    429010  curry bean salad serve flavorful refresh salad...\n",
       "2    277542  delicious steak onion marinade another try loo...\n",
       "3     78450  pork tenderloin hoisin another keeper bonnie s...\n",
       "4     80012  mix baby green oranges grapefruit avocado love..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = get_processed(sample)\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some stopwords\n",
    "#new_stopwords = ['.', '\\\"', '\\'', ':', '(', ')', ',', '-', 'etc', '1', '/', '2', '3', '\\'s', '\\'\\'''','``', '!' ]\n",
    "#stop_words.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosine'></a>\n",
    "### 2.1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = get_cos_sim_matrix(processed)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88378</td>\n",
       "      <td>445577</td>\n",
       "      <td>2012-07-25</td>\n",
       "      <td>5</td>\n",
       "      <td>Very good - we all enjoyed this.  I used just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2114486</td>\n",
       "      <td>445577</td>\n",
       "      <td>2013-07-04</td>\n",
       "      <td>3</td>\n",
       "      <td>I&amp;#039;d suggest using green curry paste, rath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900992</td>\n",
       "      <td>445577</td>\n",
       "      <td>2013-10-02</td>\n",
       "      <td>3</td>\n",
       "      <td>We added an extra jalapeno pepper and used Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2503874</td>\n",
       "      <td>129377</td>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>4</td>\n",
       "      <td>set up beautifully once it was completely cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247152</td>\n",
       "      <td>310201</td>\n",
       "      <td>2009-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>This was even better than expected, especially...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    88378     445577  2012-07-25       5   \n",
       "1  2114486     445577  2013-07-04       3   \n",
       "2   900992     445577  2013-10-02       3   \n",
       "3  2503874     129377  2012-11-16       4   \n",
       "4   247152     310201  2009-05-27       5   \n",
       "\n",
       "                                              review  \n",
       "0  Very good - we all enjoyed this.  I used just ...  \n",
       "1  I&#039;d suggest using green curry paste, rath...  \n",
       "2  We added an extra jalapeno pepper and used Tha...  \n",
       "3  set up beautifully once it was completely cool...  \n",
       "4  This was even better than expected, especially...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_processed = get_interaction_processed(processed, interactions_data)\n",
    "interactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(processed, interactions, recipe, cosine_sim,k):\n",
    "    interactions_processed = get_interaction_processed(processed, interactions)\n",
    "    uid_sample = interactions_processed['user_id'].values\n",
    "    rid_sample = interactions_processed['recipe_id'].values\n",
    "\n",
    "    all_rids = interactions_processed['recipe_id'].unique()\n",
    "    pred_rids = []\n",
    "\n",
    "    for i in range(len(interactions_processed)):\n",
    "        try:\n",
    "          recipe_ids = get_recommendation_cos(processed,\n",
    "                                                interactions_processed,\n",
    "                                                rid_sample[i],\n",
    "                                                uid_sample[i],\n",
    "                                                cosine_sim,\n",
    "                                                k)\n",
    "          pred_rids += list(recipe_ids)\n",
    "        except:\n",
    "          next\n",
    "    pred_bids = np.array(list(set(pred_rids)))\n",
    "    return len(pred_bids)/len(all_rids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  88378 2114486  900992 ...  428885  169430  369363]\n",
      "[445577 445577 445577 ... 273409 273409 273409]\n",
      "   user_id  recipe_id        date  rating  \\\n",
      "0    88378     445577  2012-07-25       5   \n",
      "1  2114486     445577  2013-07-04       3   \n",
      "2   900992     445577  2013-10-02       3   \n",
      "3  2503874     129377  2012-11-16       4   \n",
      "4   247152     310201  2009-05-27       5   \n",
      "\n",
      "                                              review  \n",
      "0  Very good - we all enjoyed this.  I used just ...  \n",
      "1  I&#039;d suggest using green curry paste, rath...  \n",
      "2  We added an extra jalapeno pepper and used Tha...  \n",
      "3  set up beautifully once it was completely cool...  \n",
      "4  This was even better than expected, especially...  \n",
      "  recipe_id                                            content\n",
      "0     94947  crab fill crescent snack find crescent roll re...\n",
      "1    429010  curry bean salad serve flavorful refresh salad...\n",
      "2    277542  delicious steak onion marinade another try loo...\n",
      "3     78450  pork tenderloin hoisin another keeper bonnie s...\n",
      "4     80012  mix baby green oranges grapefruit avocado love...\n"
     ]
    }
   ],
   "source": [
    "uid_sample = interactions_processed['user_id'].values\n",
    "rid_sample = interactions_processed['recipe_id'].values\n",
    "print(uid_sample)\n",
    "print(rid_sample)\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "print(interactions_processed.head())\n",
    "print(processed.head())\n",
    "\n",
    "for i in range(len(interactions_processed)):\n",
    "    try:\n",
    "        act, pred = get_results_cos(processed,\n",
    "                                    interactions_processed,\n",
    "                                    recipes_data,\n",
    "                                    rid_sample[i],\n",
    "                                    uid_sample[i],\n",
    "                                    cosine_sim,\n",
    "                                    5)\n",
    "        predictions_cos.append(pred)\n",
    "        actual_cos.append(act)\n",
    "    except:\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0697657531912885, MAE: 0.5\n"
     ]
    }
   ],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage: 0.738\n"
     ]
    }
   ],
   "source": [
    "cov_cos = get_coverage(processed, interactions_data, recipes_data, cosine_sim,5)\n",
    "print(f'coverage: {cov_cos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lsi'></a>\n",
    "### 2.2. LSI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mixture'></a>\n",
    "### 2.3. Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3. Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
