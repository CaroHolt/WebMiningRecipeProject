{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Mining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1. Data Preprocessing and Imports](#preprocessing)\n",
    "##### [1.1 Keyword extraction](#sampling)\n",
    "##### [1.1 Keyword extraction](#keywords)\n",
    "##### [2. Models](#models)\n",
    "###### [2.1. Cosine Similarity](#cosine)\n",
    "###### [2.2. LSI Model](#lsi)\n",
    "###### [2.3. Mixture Model](#mixture)\n",
    "##### [3. Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1. Data Preprocessing and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages to install in cmd upfront:\n",
    "\n",
    "conda install -c conda-forge selenium <\\br>\n",
    "conda install -c anaconda nltk <\\br>\n",
    "pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import inflect\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.metrics import jaccard_score, pairwise_distances_chunked, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions module\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "interactions_raw = pd.read_csv(\n",
    "        './Data/RAW_interactions.csv')\n",
    "recipes_raw = pd.read_csv(\n",
    "        './Data/RAW_recipes.csv', parse_dates=['submitted'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies so that we don't have to reload the data after mistakes\n",
    "interactions_data = interactions_raw.copy()\n",
    "recipes_data = recipes_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to more explanatory names\n",
    "recipes_data.rename(columns={\"id\": \"recipe_id\"}, inplace=True)\n",
    "\n",
    "# Fill nan\n",
    "# recipes_data.fillna(\"\", inplace=True)\n",
    "# interactions_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_NAs(df):\n",
    "    df.drop(df[df[\"name\"].isna()].index, inplace =True)\n",
    "    df[\"description\"].fillna(\"\", inplace=True)\n",
    "    df.loc[144074, \"minutes\"]= 25\n",
    "    df.drop(df[df[\"name\"]==\"how to preserve a husband\"].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_with_NAs(recipes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sampling'></a>\n",
    "### Provisory recipe filter/sampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an age column for the recipes\n",
    "recipes_data['age'] = round((2019-recipes_data.submitted.dt.year)+recipes_data.submitted.dt.month/12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ratings for each recipe\n",
    "\n",
    "def get_avg_recipe_rating(interactions_df, recipes_df):\n",
    "    #Average ratings\n",
    "    num_interactions = interactions_df.groupby(\"recipe_id\")[\"date\"].count()\n",
    "    #only consider the ratings (>0) into the mean, not the reviews w/o ratings\n",
    "    mean_ratings = round(interactions_df[interactions_df[\"rating\"]!=0].groupby(\"recipe_id\")[\"rating\"].mean(), 2)\n",
    "    #merge\n",
    "    df_rmerged = recipes_df.join(num_interactions, how=\"left\", on=\"recipe_id\").join(mean_ratings, how=\"left\", on=\"recipe_id\")\n",
    "    df_rmerged = df_rmerged.rename(columns ={\"date\":\"num_interactions\", \"rating\":\"avg_rating\"})\n",
    "    return df_rmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_byquality(df):\n",
    "    df.drop(df[(df[\"n_steps\"]==1)&(df[\"num_interactions\"]==1)].index, axis=0, inplace =True)\n",
    "    print(\"Shape after removing 1 step recipes w/ low interactions:\", df.shape)\n",
    "    df.drop(df[df[\"avg_rating\"].isna()].index, axis=0, inplace =True)\n",
    "    print(\"Shape after removing recipes w/o ratings:\", df.shape)\n",
    "    df.drop(df[(df['minutes']==0)].index, axis=0, inplace=True)\n",
    "    print('Shape after removing 0 minutes interaction w/ low interactions:', df.shape)\n",
    "\n",
    "def filter_byinteractions(num_interactions, age, df, older):\n",
    "    \"\"\"\n",
    "    older: boolean\n",
    "    \"\"\"\n",
    "    if (older==True):\n",
    "        index_remove= df[(df[\"num_interactions\"]<=num_interactions) & (df[\"age\"]>age)][\"recipe_id\"].index\n",
    "        df.drop(index_remove, axis=0, inplace=True)\n",
    "        print(f'Shape after filtering recipes less than {num_interactions} and older than {age} years old: {df.shape}')\n",
    "    else:\n",
    "        index_remove= df[(df[\"num_interactions\"]<=num_interactions) & (df[\"age\"]<=age)][\"recipe_id\"].index\n",
    "        df.drop(index_remove, axis=0, inplace=True)\n",
    "        print(f'Shape after filtering recipes less than {num_interactions} and younger than {age} years old: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best(interactions, ratings, n_dupl):\n",
    "    # number of interaction are different -> there exists a maximum\n",
    "    if((len(interactions) != len(set(interactions)))) :\n",
    "        return interactions.idxmax(axis=1)\n",
    "    else:# return the maximum rating or any of the duplicate recipes\n",
    "        return ratings.idxmax(axis=1)\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    dupl_recipes = pd.DataFrame(df[df[\"name\"].duplicated(keep=False)])\n",
    "    dupl_rgrouped= dupl_recipes.groupby('name').groups\n",
    "    \n",
    "    to_keep = []\n",
    "    \n",
    "    for name in dupl_rgrouped:\n",
    "        n_dupl = len(dupl_rgrouped[name])\n",
    "        if(n_dupl == 2):\n",
    "            index1=dupl_rgrouped[name][0]\n",
    "            index2=dupl_rgrouped[name][1]\n",
    "            \n",
    "            interactions = dupl_recipes.loc[[index1, index2], ['num_interactions']].num_interactions\n",
    "            ratings = dupl_recipes.loc[[index1, index2], ['avg_rating']].avg_rating\n",
    "            to_keep.append(choose_best(interactions, ratings, n_dupl))\n",
    "        elif (n_dupl==3):\n",
    "            index1=dupl_rgrouped[name][0]\n",
    "            index2=dupl_rgrouped[name][1]\n",
    "            index3=dupl_rgrouped[name][2]\n",
    "            \n",
    "            interactions = dupl_recipes.loc[[index1, index2, index3], ['num_interactions']].num_interactions\n",
    "            ratings = dupl_recipes.loc[[index1, index2, index3], ['avg_rating']].avg_rating\n",
    "            to_keep.append(choose_best(interactions, ratings, n_dupl))\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "            break\n",
    "            \n",
    "        df.drop(df.index.intersection(to_keep), axis=0, inplace=True)\n",
    "    print('Shape after dropping duplicates:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate URL for every recipe\n",
    "def generate_URL(df):\n",
    "    df[\"URL\"] = df.apply(lambda row: \"https://www.food.com/recipe/\"+\" \".join(row[\"name\"].split()).replace(\" \", \"-\") \n",
    "                         +\"-\"+str(row[\"recipe_id\"]), axis=1)\n",
    "    print(f'URLs created for each of the {len(df.index)} recipes')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering recipes less than 15 and older than 8 years old: (21913, 15)\n",
      "Shape after filtering recipes less than 10 and younger than 8 years old: (11151, 15)\n",
      "Shape after removing 1 step recipes w/ low interactions: (11151, 15)\n",
      "Shape after removing recipes w/o ratings: (11151, 15)\n",
      "Shape after removing 0 minutes interaction w/ low interactions: (11103, 15)\n",
      "Shape after dropping duplicates: (11090, 15)\n",
      "URLs created for each of the 11090 recipes\n"
     ]
    }
   ],
   "source": [
    "recipes_data = get_avg_recipe_rating(interactions_data, recipes_data)\n",
    "filter_byinteractions(15,8,recipes_data, older=True)\n",
    "filter_byinteractions(10,8,recipes_data, older=False)\n",
    "filter_byquality(recipes_data)\n",
    "remove_duplicates(recipes_data)\n",
    "recipes_data = generate_URL(recipes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>['lean pork chops', 'flour', 'salt', 'dry must...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>25775</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['preheat oven to 350 degrees', 'place spinach...</td>\n",
       "      <td>if spinach scares you, this is one recipe that...</td>\n",
       "      <td>['frozen chopped spinach', 'egg', 'salt', 'bla...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>58224</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown the meat &amp; drain fat', 'stir in sugar ...</td>\n",
       "      <td>just the thing for a day when you're wanton so...</td>\n",
       "      <td>['ground beef', 'sugar', 'prepared yellow must...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>land of nod  cinnamon buns</td>\n",
       "      <td>22526</td>\n",
       "      <td>35</td>\n",
       "      <td>29212</td>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['before you turn in for the night , grease a ...</td>\n",
       "      <td>i have made this several times and it's dead e...</td>\n",
       "      <td>['rolls', 'brown sugar', 'instant vanilla pudd...</td>\n",
       "      <td>6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>51</td>\n",
       "      <td>4.73</td>\n",
       "      <td>https://www.food.com/recipe/land-of-nod-cinnam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>never weep  whipped cream</td>\n",
       "      <td>74805</td>\n",
       "      <td>5</td>\n",
       "      <td>87877</td>\n",
       "      <td>2003-11-01</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['whip all ingredients together until firm pea...</td>\n",
       "      <td>i don't know where i got this, but it works. t...</td>\n",
       "      <td>['whipping cream', 'vanilla instant pudding mi...</td>\n",
       "      <td>4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>https://www.food.com/recipe/never-weep-whipped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  recipe_id  minutes  \\\n",
       "15                   chicken lickin  good  pork chops      63986      500   \n",
       "36  how i got my family to eat spinach  spinach ca...      25775       50   \n",
       "43              immoral  sandwich filling  loose meat      58224       35   \n",
       "53                         land of nod  cinnamon buns      22526       35   \n",
       "67                          never weep  whipped cream      74805        5   \n",
       "\n",
       "    contributor_id  submitted  \\\n",
       "15           14664 2003-06-06   \n",
       "36           37305 2002-04-22   \n",
       "43           37183 2003-04-04   \n",
       "53           29212 2002-03-14   \n",
       "67           87877 2003-11-01   \n",
       "\n",
       "                                                 tags  \\\n",
       "15  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "36  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "43  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "53  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "67  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                       nutrition  n_steps  \\\n",
       "15        [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "36     [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "43      [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "53  [575.3, 18.0, 116.0, 34.0, 28.0, 22.0, 34.0]        7   \n",
       "67       [276.3, 45.0, 2.0, 1.0, 3.0, 91.0, 0.0]        4   \n",
       "\n",
       "                                                steps  \\\n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "36  ['preheat oven to 350 degrees', 'place spinach...   \n",
       "43  ['brown the meat & drain fat', 'stir in sugar ...   \n",
       "53  ['before you turn in for the night , grease a ...   \n",
       "67  ['whip all ingredients together until firm pea...   \n",
       "\n",
       "                                          description  \\\n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "36  if spinach scares you, this is one recipe that...   \n",
       "43  just the thing for a day when you're wanton so...   \n",
       "53  i have made this several times and it's dead e...   \n",
       "67  i don't know where i got this, but it works. t...   \n",
       "\n",
       "                                          ingredients  n_ingredients   age  \\\n",
       "15  ['lean pork chops', 'flour', 'salt', 'dry must...              7  16.5   \n",
       "36  ['frozen chopped spinach', 'egg', 'salt', 'bla...              8  17.3   \n",
       "43  ['ground beef', 'sugar', 'prepared yellow must...              8  16.3   \n",
       "53  ['rolls', 'brown sugar', 'instant vanilla pudd...              6  17.2   \n",
       "67  ['whipping cream', 'vanilla instant pudding mi...              4  16.9   \n",
       "\n",
       "    num_interactions  avg_rating  \\\n",
       "15                19        4.88   \n",
       "36               113        4.34   \n",
       "43                21        4.20   \n",
       "53                51        4.73   \n",
       "67                80        4.99   \n",
       "\n",
       "                                                  URL  \n",
       "15  https://www.food.com/recipe/chicken-lickin-goo...  \n",
       "36  https://www.food.com/recipe/how-i-got-my-famil...  \n",
       "43  https://www.food.com/recipe/immoral-sandwich-f...  \n",
       "53  https://www.food.com/recipe/land-of-nod-cinnam...  \n",
       "67  https://www.food.com/recipe/never-weep-whipped...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='keywords'></a>\n",
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ingredients and save as String\n",
    "for index, row in recipes_data.iterrows():\n",
    "    ingredientlist = row['ingredients']\n",
    "    ingredientlist = row['ingredients'].replace('[', '').replace(', ', '').replace(']', '').replace('and', '\\'').split(\"\\'\")\n",
    "    ingredientlist = list(filter(None, ingredientlist))\n",
    "    ingredientlistString = \"\"\n",
    "    for i in ingredientlist:\n",
    "        ingredientlistString = ingredientlistString + i\n",
    "    recipes_data.at[index, 'ingredients'] = ingredientlistString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords for free text features\n",
    "# recipes_data = get_keywords(recipes_data, \"steps\", \"steps_keywords\")\n",
    "# recipes_data = get_keywords(recipes_data, \"description\", \"description_keywords\")\n",
    "# interactions_data = get_keywords(interactions_data, \"review\", \"review_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>age</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>lean pork chopsfloursaltdry mustardgarlic powd...</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19</td>\n",
       "      <td>4.88</td>\n",
       "      <td>https://www.food.com/recipe/chicken-lickin-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>how i got my family to eat spinach  spinach ca...</td>\n",
       "      <td>25775</td>\n",
       "      <td>50</td>\n",
       "      <td>37305</td>\n",
       "      <td>2002-04-22</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['preheat oven to 350 degrees', 'place spinach...</td>\n",
       "      <td>if spinach scares you, this is one recipe that...</td>\n",
       "      <td>frozen chopped spinacheggsaltblack pepperonion...</td>\n",
       "      <td>8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>113</td>\n",
       "      <td>4.34</td>\n",
       "      <td>https://www.food.com/recipe/how-i-got-my-famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immoral  sandwich filling  loose meat</td>\n",
       "      <td>58224</td>\n",
       "      <td>35</td>\n",
       "      <td>37183</td>\n",
       "      <td>2003-04-04</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown the meat &amp; drain fat', 'stir in sugar ...</td>\n",
       "      <td>just the thing for a day when you're wanton so...</td>\n",
       "      <td>ground beefsugarprepared yellow mustardbeercay...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.20</td>\n",
       "      <td>https://www.food.com/recipe/immoral-sandwich-f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  recipe_id  minutes  \\\n",
       "15                   chicken lickin  good  pork chops      63986      500   \n",
       "36  how i got my family to eat spinach  spinach ca...      25775       50   \n",
       "43              immoral  sandwich filling  loose meat      58224       35   \n",
       "\n",
       "    contributor_id  submitted  \\\n",
       "15           14664 2003-06-06   \n",
       "36           37305 2002-04-22   \n",
       "43           37183 2003-04-04   \n",
       "\n",
       "                                                 tags  \\\n",
       "15  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "36  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "43  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "15     [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "36  [166.1, 16.0, 6.0, 32.0, 19.0, 26.0, 3.0]        5   \n",
       "43   [223.2, 22.0, 4.0, 7.0, 35.0, 30.0, 0.0]        6   \n",
       "\n",
       "                                                steps  \\\n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "36  ['preheat oven to 350 degrees', 'place spinach...   \n",
       "43  ['brown the meat & drain fat', 'stir in sugar ...   \n",
       "\n",
       "                                          description  \\\n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "36  if spinach scares you, this is one recipe that...   \n",
       "43  just the thing for a day when you're wanton so...   \n",
       "\n",
       "                                          ingredients  n_ingredients   age  \\\n",
       "15  lean pork chopsfloursaltdry mustardgarlic powd...              7  16.5   \n",
       "36  frozen chopped spinacheggsaltblack pepperonion...              8  17.3   \n",
       "43  ground beefsugarprepared yellow mustardbeercay...              8  16.3   \n",
       "\n",
       "    num_interactions  avg_rating  \\\n",
       "15                19        4.88   \n",
       "36               113        4.34   \n",
       "43                21        4.20   \n",
       "\n",
       "                                                  URL  \n",
       "15  https://www.food.com/recipe/chicken-lickin-goo...  \n",
       "36  https://www.food.com/recipe/how-i-got-my-famil...  \n",
       "43  https://www.food.com/recipe/immoral-sandwich-f...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='user-interaction'></a>\n",
    "### Creating user-activity data & filtered interactions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data flow:\n",
    "\n",
    "filter_interactions_data() -(calls)-> \n",
    "    (impute_average_rating(), (create_activity_data() \n",
    "                                        -(calls)-> get_user_activity_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_average_rating(row, df_uactivity):\n",
    "    if (row['rating'] == 0):\n",
    "        imputed_rating = round(df_uactivity.loc[df_uactivity.user_id == row.user_id, 'uavg_rating'].values[0], 0)\n",
    "        return imputed_rating\n",
    "    else:\n",
    "        return row.rating\n",
    "\n",
    "def get_user_activity_df(df):\n",
    "    #Create a user activity dataframe\n",
    "    df_uactivity = df.groupby('user_id')['rating'].value_counts().unstack().fillna(0)\n",
    "    cols = list(df_uactivity)\n",
    "    df_uactivity['total_interactions'] = df_uactivity[cols].sum(axis=1)\n",
    "    df_uactivity['total_ratings'] = df_uactivity['total_interactions']-df_uactivity[0]\n",
    "    return df_uactivity\n",
    "\n",
    "def create_activity_data(interactions_df, num_interactions):\n",
    "    df_uactivity = get_user_activity_df(interactions_df[['recipe_id','user_id', 'rating']])\n",
    "    df_uactivity = df_uactivity[df_uactivity['total_interactions']>=7]\n",
    "    print(f'Shape after filtering out users with less than {num_interactions} interactions: {df_uactivity.shape}')\n",
    "    #create average user ratings as behavior\n",
    "    df_uactivity['uavg_rating'] = df_uactivity.iloc[:,1:6].apply(\n",
    "        lambda row: np.round(np.ma.average(list(range(1,6)), \n",
    "                                           weights = (row[1], row[2], row[3], row[4], row[5])),1), axis = 1)\n",
    "    \n",
    "    df_uactivity = df_uactivity.reset_index()\n",
    "    df_uactivity.columns.set_names(None, inplace = True)\n",
    "    \n",
    "    #drop users that only have only reviews but no ratings\n",
    "    df_uactivity.drop(df_uactivity[df_uactivity.total_ratings == 0].index, inplace=True, axis=0)\n",
    "    return df_uactivity\n",
    "\n",
    "def filter_interactions_data(interactions_df, recipes_data, num_interactions):\n",
    "    df_uactivity = create_activity_data(interactions_df, num_interactions)\n",
    "    # 1. Create Filter for interations with filtered df_uactivity -> Only interactions from active users remain\n",
    "    user_filter = pd.merge(df_uactivity[['user_id']], interactions_data[['recipe_id','user_id', 'rating']], how = 'left', on ='user_id')\n",
    "    # 2. Filter interactions with active recipes -> Only interactions from active users and clean recipes remain\n",
    "    interactions = pd.merge(recipes_data[['recipe_id']], user_filter[['recipe_id', 'user_id', 'rating']], on = 'recipe_id', how ='inner')\n",
    "    zero_ratings = len(interactions.loc[interactions.rating==0])\n",
    "    interactions['rating'] = interactions.apply(lambda row: impute_average_rating(row, df_uactivity), axis=1)\n",
    "    print(f'Number of imputed ratings: {zero_ratings}')\n",
    "    return interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering out users with less than 7 interactions: (17099, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py:628: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg = np.multiply(a, wgt, dtype=result_dtype).sum(axis)/scl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of imputed ratings: 8169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63986</td>\n",
       "      <td>4470</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63986</td>\n",
       "      <td>28649</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63986</td>\n",
       "      <td>37471</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63986</td>\n",
       "      <td>60992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63986</td>\n",
       "      <td>75497</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  user_id  rating\n",
       "0      63986     4470     5.0\n",
       "1      63986    28649     4.0\n",
       "2      63986    37471     5.0\n",
       "3      63986    60992     5.0\n",
       "4      63986    75497     5.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = filter_interactions_data(interactions_data, recipes_data, num_interactions=7)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_dist(df_column):\n",
    "    ratings_series=pd.Series(df_column.value_counts())\n",
    "    ratings_series.plot.bar()\n",
    "    print(f'Percent of 5 star rating interactions: {round((ratings_series.loc[5]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 4 star rating interactions: {round((ratings_series.loc[4]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 3 star rating interactions: {round((ratings_series.loc[3]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 2 star rating interactions: {round((ratings_series.loc[2]/len(df_column)*100),2)}%')\n",
    "    print(f'Percent of 1 star rating interactions: {round((ratings_series.loc[1]/len(df_column)*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of 5 star rating interactions: 79.63%\n",
      "Percent of 4 star rating interactions: 15.58%\n",
      "Percent of 3 star rating interactions: 3.29%\n",
      "Percent of 2 star rating interactions: 1.03%\n",
      "Percent of 1 star rating interactions: 0.47%\n"
     ]
    }
   ],
   "source": [
    "#Let's look at the distribution of ratings\n",
    "get_rating_dist(interactions.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LiY140\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LiY140\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LiY140\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://github.com/nding17/YelpRecommendation/blob/master/notebooks/Content%20Based%20Models.ipynb\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_special(words):\n",
    "    \"\"\"Remove special signs like &*\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[-,$()#+&*]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"  \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    myStopWords = []\n",
    "    stopwords.extend(myStopWords)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert words to lowercase\"\"\"\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize_lemmatize(words):\n",
    "    words = remove_special(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    #words = stem_words(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words\n",
    "\n",
    "def get_processed(data):\n",
    "    processed = pd.DataFrame(data=[],columns = ['recipe_id', 'content'])\n",
    "    new_texts = []\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        recipe_id = data['recipe_id'].iloc[i]\n",
    "        words = nltk.word_tokenize(data['content'].iloc[i])\n",
    "        text = ' '.join(normalize_lemmatize(words))\n",
    "        dfnew = pd.DataFrame([[recipe_id, text]], columns=['recipe_id', 'content'])\n",
    "        new_texts.append(text)\n",
    "        processed = processed.append(dfnew,ignore_index = True)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input (df, column_names):\n",
    "    df_content = df\n",
    "    df_content['content'] = df.loc[:, (column_names)].apply(lambda texts: ' '.join(texts), axis=1)\n",
    "    df_content.drop(columns = column_names, inplace = True)\n",
    "    df_content['content']=df_content['content'].apply(lambda text: ' '.join(text.split()))\n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11090, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11090, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all recipes are in interactions\n",
    "helper = pd.unique(interactions_data['recipe_id'])\n",
    "df_rfiltered = recipes_data[recipes_data.recipe_id.isin(helper)]\n",
    "print(recipes_data.shape)\n",
    "df_rfiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63986</td>\n",
       "      <td>chicken lickin good pork chops here's and old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25775</td>\n",
       "      <td>how i got my family to eat spinach spinach cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>58224</td>\n",
       "      <td>immoral sandwich filling loose meat just the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>22526</td>\n",
       "      <td>land of nod cinnamon buns i have made this sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>74805</td>\n",
       "      <td>never weep whipped cream i don't know where i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recipe_id                                            content\n",
       "15      63986  chicken lickin good pork chops here's and old ...\n",
       "36      25775  how i got my family to eat spinach spinach cas...\n",
       "43      58224  immoral sandwich filling loose meat just the t...\n",
       "53      22526  land of nod cinnamon buns i have made this sev...\n",
       "67      74805  never weep whipped cream i don't know where i ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten steps data\n",
    "df_rfiltered.steps = df_rfiltered.loc[:, ('steps')].str.replace(\"\\[\", \"\").str.replace(\"'\", \"\").str.replace(\"\\]\", \"\").str.replace(\",\",\"\").copy()\n",
    "\n",
    "#create content df\n",
    "df_rfiltered = create_input(df_rfiltered[['recipe_id', 'name', 'description', 'steps']], ['name', 'description', 'steps'])\n",
    "\n",
    "df_rfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now process content\n",
    "content_processed = get_processed(df_rfiltered)\n",
    "content_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df_content.sample(n=1000, replace=False, random_state=42)\\\n",
    "#                  .reset_index()\\\n",
    "#                  .drop(columns=['index'])\n",
    "# sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Recommendations functions for Coverage & Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return top k predicted ratings in readable form \n",
    "\n",
    "# IMPORTANT: must set the dataframe for recipe_info index == recipe_id!\n",
    "def get_user_recommendations(user_id, similarity, content, interactions, recipe_info, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    info:\n",
    "        HTML dataframe with recommendation information\n",
    "    \"\"\"\n",
    "    #get top k recipe ids\n",
    "    topk_recipes, predictions, recipeurls, imageurls = get_topk_recipes(user_id, similarity, content, interactions, k)\n",
    "    info = recipe_info.loc[topk_recipes]\n",
    "    info = info[['name', 'minutes', 'submitted', 'description']]\n",
    "    info['prediction'] = predictions\n",
    "    info['recipeurl'] = recipeurls\n",
    "    info['imageurl'] = imageurls\n",
    "    for index, row in info.iterrows():\n",
    "        info.at[index, 'recipeurl'] = '<a href=\"'+ row['recipeurl'] + '\">'+row['recipeurl'] +'</a>'\n",
    "        info.at[index, 'imageurl'] = '<a href=\"'+ row['imageurl'] + '\"> Image of recipe '+str(index)+'</a>'\n",
    "    info = HTML(info.to_html(escape=False))\n",
    "    return info\n",
    "\n",
    "def get_topk_recipes(user_id, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    topk_recipes:\n",
    "        array of top k recipe ids\n",
    "    predictions:\n",
    "        array with top k predictions\n",
    "    recipeurls:\n",
    "        array with top k recipe urls\n",
    "    imageurls:\n",
    "        array with top k recipe imageurls\n",
    "    \"\"\"\n",
    "    prediction_df = get_user_preference(user_id,similarity, content, interactions)\n",
    "    #take only the not yet seen recipes\n",
    "    new_predictions = prediction_df[prediction_df['has_rated'] == False]\n",
    "    #sort predictions\n",
    "    ordered_predictions = new_predictions.sort_values(by='prediction', ascending=False)\n",
    "    #get recipe_id array\n",
    "    topk_recipes = ordered_predictions.index[:k].values\n",
    "    imageurls = []\n",
    "    recipeurls = []\n",
    "    for entry in topk_recipes:\n",
    "        recipeurls.append(\"https://www.food.com/recipe/\" + str(entry))\n",
    "        imageurls.append(get_image_source_url(entry))\n",
    "    predictions = ordered_predictions.prediction[:k].values\n",
    "    return topk_recipes, predictions, recipeurls, imageurls\n",
    "\n",
    "#return predictions for 1 user\n",
    "def get_user_preference(user_id, similarity, content, interactions_data):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    prediction_df:\n",
    "        DataFrame in with columns ['recipe_id','prediction', 'has_rated'] for 1 user\n",
    "    \"\"\"\n",
    "    #prepare similarity dataframe\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions_data.loc[interactions_data['user_id']==user_id, 'recipe_id'].values\n",
    "    #get similarities of ALL recipes w/ already rated recipes of user\n",
    "    sim_rated_all = sim.loc[rated_recipes, :]\n",
    "    #get ratings of already rated recipes\n",
    "    ratings = get_reshaped_ratings(user_id, interactions_data)\n",
    "    \n",
    "    #compute weighted similarities between all recipes and already rated recipes\n",
    "    weighted_sim = np.dot(ratings,sim_rated_all)\n",
    "    #compute normalization constant\n",
    "    norm_const = np.array(np.abs(sim_rated_all).sum(axis=0))\n",
    "    #return sorted predictions\n",
    "    pref_predictions = weighted_sim/norm_const\n",
    "    \n",
    "    flat_predictions = [item for sublist in pref_predictions for item in sublist]\n",
    "    #return df with recipe id also\n",
    "    prediction_df = pd.DataFrame(flat_predictions, index =content['recipe_id'].values, columns =['prediction'])\n",
    "    #indicate the already tried recipes\n",
    "    prediction_df['has_rated'] = prediction_df.index.isin(rated_recipes)\n",
    "    #order predictions\n",
    "    return prediction_df\n",
    "\n",
    "#arrange ratings for matrix multiplication\n",
    "def get_reshaped_ratings(user_id, interactions_data):\n",
    "    ratings = interactions_data[interactions_data['user_id']==user_id]\n",
    "    ratings.set_index('recipe_id', inplace=True)\n",
    "    ratings.index.set_names(None, inplace = True)\n",
    "    ratings.drop(columns='user_id', inplace=True)\n",
    "    ratings = ratings.transpose()\n",
    "    ratings.rename(index={'rating':user_id}, inplace=True)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "\n",
    "def make_all_recommendations(user_ids, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    --------\n",
    "    user_ids: Array\n",
    "        list of user ids\n",
    "    similarity: Array \n",
    "        similarity matrix with shape (#recipes, #recipes).\n",
    "    content: DataFrame\n",
    "        processed DataFrame with ['recipe_id', 'content'] used to fetch all recipes ids to make recommendations for \n",
    "        (=total training data)\n",
    "    interactions: DataFrame\n",
    "        preprocessed interactions DataFrame ['recipe_id', 'user_id', 'rating']     \n",
    "    k: integer\n",
    "        number of recommendations to make\n",
    "    Returns:\n",
    "    --------\n",
    "    nested_recommendations:\n",
    "        nested list of recommended recipe_ids for each user in param list\n",
    "        example:[[rid1, rid20, rid30...], [rid1, rid20, rid30...],[rid1, rid20, rid30...]]\n",
    "    \"\"\"\n",
    "    pbar = ProgressBar()\n",
    "    nested_recommendations=[]\n",
    "    for i in pbar(range(len(user_ids))):\n",
    "        recs = get_topk_recipes_lean(user_ids[i], similarity, content, interactions, k)\n",
    "        nested_recommendations.append(recs)\n",
    "    return nested_recommendations\n",
    "\n",
    "def get_topk_recipes_lean(user_id, similarity, content, interactions, k):\n",
    "    \"\"\"\n",
    "     Returns\n",
    "    ----------\n",
    "    topk_recipes:\n",
    "        array of top k recipe ids\n",
    "    predictions:\n",
    "        array with top k predictions\n",
    "    recipeurls:\n",
    "        array with top k recipe urls\n",
    "    imageurls:\n",
    "        array with top k recipe imageurls\n",
    "    \"\"\"\n",
    "    prediction_df = get_user_preference(user_id,similarity, content, interactions)\n",
    "    #take only the not yet seen recipes\n",
    "    new_predictions = prediction_df.loc[prediction_df['has_rated'] == False, :]\n",
    "    #sort predictions\n",
    "    ordered_predictions = new_predictions.sort_values(by='prediction', ascending=False)\n",
    "    #get recipe_id array\n",
    "    topk_recipes = ordered_predictions.index[:k].values\n",
    "    #predictions = ordered_predictions.prediction[:k].values\n",
    "    return topk_recipes\n",
    "\n",
    "# def get_user_recommendations_lean(user_id, similarity, content, interactions, recipe_info, k):\n",
    "#     \"\"\"\n",
    "#      Returns\n",
    "#     ----------\n",
    "#     info:\n",
    "#         HTML dataframe with recommendation information\n",
    "#     \"\"\"\n",
    "#     #get top k recipe ids\n",
    "#     topk_recipes, predictions = get_topk_recipes_lean(user_id, similarity, content, interactions, k)\n",
    "#     info = recipe_info.loc[topk_recipes]\n",
    "#     info = info[['name', 'minutes', 'submitted', 'description']]\n",
    "#     info['prediction'] = predictions\n",
    "#     return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://github.com/statisticianinstilettos/recmetrics/\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# input = nested_recommendations from make_all_recommendations\n",
    "def catalog_coverage(predicted, catalog, k):\n",
    "    \"\"\"\n",
    "    Computes the catalog coverage for k lists of recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    catalog: list\n",
    "        A list of all unique items in the training data\n",
    "        example: ['A', 'B', 'C', 'X', 'Y', Z]\n",
    "    k: integer\n",
    "        The number of observed recommendation lists\n",
    "        which randomly choosed in our offline setup\n",
    "    Returns\n",
    "    ----------\n",
    "    catalog_coverage:\n",
    "        The catalog coverage of the recommendations as a percent\n",
    "        rounded to 2 decimal places\n",
    "    ----------    \n",
    "    Metric Defintion:\n",
    "    Ge, M., Delgado-Battenfeld, C., & Jannach, D. (2010, September).\n",
    "    Beyond accuracy: evaluating recommender systems by coverage and serendipity.\n",
    "    In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). ACM.\n",
    "    \"\"\"\n",
    "    sampling = random.choices(predicted, k=k)\n",
    "    predicted_flattened = [p for sublist in sampling for p in sublist]\n",
    "    L_predictions = len(set(predicted_flattened))\n",
    "    catalog_coverage = round(L_predictions/(len(catalog)*1.0)*100,2)\n",
    "    return catalog_coverage\n",
    "\n",
    "def personalization(predicted):\n",
    "    \"\"\"\n",
    "    Personalization measures recommendation similarity across users.\n",
    "    A high score indicates good personalization (user's lists of recommendations are different).\n",
    "    A low score indicates poor personalization (user's lists of recommendations are very similar).\n",
    "    A model is \"personalizing\" well if the set of recommendations for each user is different.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    predicted : a list of lists\n",
    "        Ordered predictions\n",
    "        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n",
    "    Returns:\n",
    "    -------\n",
    "        The personalization score for all recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_rec_matrix(predicted):\n",
    "        df = pd.DataFrame(data=predicted).reset_index().melt(\n",
    "            id_vars='index', value_name='item',\n",
    "        )\n",
    "        df = df[['index', 'item']].pivot(index='index', columns='item', values='item')\n",
    "        df = pd.notna(df)*1\n",
    "        rec_matrix = sp.csr_matrix(df.values)\n",
    "        return rec_matrix\n",
    "\n",
    "    #create matrix for recommendations\n",
    "    predicted = np.array(predicted)\n",
    "    rec_matrix_sparse = make_rec_matrix(predicted)\n",
    "\n",
    "    #calculate similarity for every user's recommendation list\n",
    "    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n",
    "\n",
    "    #get indicies for upper right triangle w/o diagonal\n",
    "    upper_right = np.triu_indices(similarity.shape[0], k=1)\n",
    "\n",
    "    #calculate average similarity\n",
    "    personalization = np.mean(similarity[upper_right])\n",
    "    return 1-personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Prediction function for RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for 1 already rated recipe based on similarities to other already rated recipes\n",
    "\n",
    "def get_one_prediction(similarity, content, interactions, user_id, recipe_id):\n",
    "    sim = pd.DataFrame(similarity, index=content['recipe_id'].values, columns=content['recipe_id'].values)\n",
    "    #get already rated recipes of user\n",
    "    rated_recipes = interactions[interactions['user_id']==user_id]['recipe_id'].values\n",
    "    #get similarities of to be predicted recipe rating with already rated recipes by user x\n",
    "    sim_rated = sim.loc[sim.index==recipe_id, rated_recipes].loc[recipe_id].values\n",
    "    #get ratings of rated recipes\n",
    "    ratings = interactions[interactions['user_id']==user_id]['rating'].values\n",
    "    \n",
    "    actual = interactions.loc[(interactions.user_id==user_id) & (interactions.recipe_id==recipe_id)]['rating'].values[0]\n",
    "    prediction = np.dot(ratings, sim_rated) /np.array([np.abs(sim_rated).sum(axis=0)])\n",
    "    return actual, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array):\n",
    "    predictions_cos = []\n",
    "    actual_cos = []\n",
    "    pbar = ProgressBar()\n",
    "    \n",
    "    for i in pbar(range(num_interactions)):\n",
    "        act, pred = get_one_prediction(similarity, content, interactions, uid_array[i], rids_array[i])\n",
    "        predictions_cos.append(pred)\n",
    "        actual_cos.append(act)\n",
    "        \n",
    "    return predictions_cos, actual_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#only relevant if there is a recipe sample\n",
    "\n",
    "def get_interaction_processed(processed, interactions):\n",
    "    #fetch only interactions in the preprocessed sample\n",
    "    interactions_processed = interactions.loc[interactions.recipe_id.isin(processed.recipe_id)]\\\n",
    "                           .reset_index()\\\n",
    "                           .drop(columns=['index'])\n",
    "    print(f'Interactions before processing: {len(interactions.index)}\\nInteractions covered in sample: {len(interactions_processed.index)}')\n",
    "    return interactions_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosine'></a>\n",
    "### 2.1. Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Tfidf & SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim_matrix(processed, n_components):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    processed['content'] = processed['content'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(processed['content'])\n",
    "    #reduce dimensionality of tfidf matrix\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    tfidf_truncated = svd.fit_transform(tfidf_matrix) \n",
    "    cosine_sim = cosine_similarity(tfidf_truncated,tfidf_truncated)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 11090)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = get_cos_sim_matrix(content_processed, 10)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.1 Make all recommendations for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16894 of 16894) |##################| Elapsed Time: 0:17:15 Time:  0:17:15\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "nested_recommendations = make_all_recommendations(interactions['user_id'].drop_duplicates().values, cosine_sim, content_processed, interactions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_coverage(nested_recommendations, content_processed.recipe_id.values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965328959870688"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalization(nested_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.2 Make all predictions for tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cos, actual_cos = make_all_predictions(len(interactions), cosine_sim, content_processed, interactions, \n",
    "                                            interactions['user_id'].values, interactions['recipe_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating'] = [item for sublist in predictions_cos for item in sublist]\n",
    "get_rating_dist(round(interactions.predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.3 Optimize n_components of tfidf/SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_cos_param(n_components, similarity, content, interactions, uid_array, rids_array):\n",
    "    rmse_mix = []\n",
    "    \n",
    "    predictions, actuals = make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array)\n",
    "    rmse = mean_squared_error(predictions, actuals)**0.5\n",
    "    rmse_mix.append(rmse)\n",
    "    return rmse_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_cos_param(n_components, content, interactions, uid_array, rids_array, k):\n",
    "    rmse_cos = []\n",
    "    coverage_cos = []\n",
    "    personalization_cos =[]\n",
    "    \n",
    "    for n in n_components:\n",
    "        similarity = get_cos_sim_matrix(content, n_components)\n",
    "        \n",
    "        predictions, actuals = make_all_predictions(num_interactions, similarity, content, interactions, uid_array, rids_array)\n",
    "        rmse = mean_squared_error(predictions, actuals)**0.5\n",
    "        rmse_cos.append(rmse)\n",
    "        \n",
    "        nested_recommendations = make_all_recommendations(uid_array.drop_duplicates(), \n",
    "                                                          similarity, \n",
    "                                                          content, \n",
    "                                                          interactions, \n",
    "                                                          k)\n",
    "        coverage = catalog_coverage(nested_recommendations, content.recipe_id.values, k)\n",
    "        pers = personalization(nested_recommendations)\n",
    "        \n",
    "        coverage_cos.append(coverage)\n",
    "        personalization_cos.append(pers)\n",
    "           \n",
    "return rmse_cos, coverage_cos, personalization_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cos_tune, coverage_cos_tune, personalization_cos = tuning_mix_param(n_components,\n",
    "                                                                         cosine_sim,\n",
    "                                                                         content_processed,\n",
    "                                                                         interactions,\n",
    "                                                                         uid_array,\n",
    "                                                                         rids_array)\n",
    "rmse_cos_min = min(rmse_cos_tune)\n",
    "rmse_cos_min_idx = rmse_cos_tune.index(rmse_cos_min)\n",
    "n_components_min = n_components[rmse_cos_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_components, rmse_cos_tune)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for different tfidv/SVD models')\n",
    "plt.plot([n_components_min], [rmse_cos_min], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_tweet_tokenized = [nltk.tokenize.TweetTokenizer().tokenize(t) for t in content_processed['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "\n",
    "# Initialize Word2Vec Model\n",
    "model = Word2Vec()\n",
    "model.build_vocab(train_texts_tweet_tokenized)\n",
    "\n",
    "# Train with the corpus\n",
    "model.train(processed_embedding, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "word_vectors = model.wv\n",
    "fname = get_tmpfile(\"word_vectors.kv\")\n",
    "word_vectors.save(fname)\n",
    "word_vectors = KeyedVectors.load(fname, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_tweet_tokenized_embedded = [[word_vectors[w] for w in t if w in word_vectors] for t in train_texts_tweet_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_texts_tweet_tokenized_embedded_averaged = [np.average(t, axis=0) for t in train_texts_tweet_tokenized_embedded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(train_texts_tweet_tokenized_embedded_averaged, train_texts_tweet_tokenized_embedded_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recipes_data.set_index('recipe_id', inplace=True)\n",
    "\n",
    "get_user_recommendations(60992, similarity_matrix, content_processed, interactions, recipes_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_cos = []\n",
    "actual_cos = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "for i in pbar(range(len(interactions))):\n",
    "    act, pred = get_one_prediction(similarity_matrix, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_cos.append(pred)\n",
    "    actual_cos.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cos = mean_squared_error(predictions_cos, actual_cos)**0.5\n",
    "mae_cos = mean_absolute_error(predictions_cos, actual_cos)\n",
    "print(f'RMSE: {rmse_cos}, MAE: {mae_cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating'] = [item for sublist in predictions_cos for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation -> =/= already rated -> Coverage\n",
    "= recommend highest predicted rating NOT seen yet\n",
    "-> new prediction for ALL recipes for 1 user\n",
    "\n",
    "\n",
    "<-> Prediction -> RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mixture'></a>\n",
    "### 2.2. Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data = recipes_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_sim_matrix(processed, lmbda, df_rfiltered):\n",
    "    cos_sim = get_cos_sim_matrix(processed)\n",
    "    df_sub = df_rfiltered[['recipe_id', 'n_steps', 'minutes', 'n_ingredients']]\n",
    "    df_processed = df_sub[df_sub['recipe_id'].isin(processed['recipe_id'])]\\\n",
    "                                                             .set_index('recipe_id')\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_processed)\n",
    "    eucl_dis = euclidean_distances(X,X)\n",
    "    eucl_sim = 1/np.exp(eucl_dis)\n",
    "    mixed_sim = np.add(cos_sim*lmbda,eucl_sim*(1-lmbda)) # assume equally weighted\n",
    "    return mixed_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 11090)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_sim = get_mix_sim_matrix(content_processed, 0.5, recipes_data)\n",
    "mixed_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make recommendations based on Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_data.set_index('recipe_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LiY140\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "      <th>recipeurl</th>\n",
       "      <th>imageurl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52840</th>\n",
       "      <td>cocoa buttermilk cake</td>\n",
       "      <td>50</td>\n",
       "      <td>2003-01-30</td>\n",
       "      <td>i adopted this recipe 9/06.  it is incredible....</td>\n",
       "      <td>4.894781</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/52840\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24612</th>\n",
       "      <td>five flavor pound cake</td>\n",
       "      <td>110</td>\n",
       "      <td>2002-04-08</td>\n",
       "      <td>i just tried this cake for the first time at f...</td>\n",
       "      <td>4.894238</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/24612\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90203</th>\n",
       "      <td>dark chocolate cake with a raspberry filling</td>\n",
       "      <td>75</td>\n",
       "      <td>2004-04-30</td>\n",
       "      <td>this is a fudgey, brownie-like cake with a cho...</td>\n",
       "      <td>4.893381</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/90203\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113914</th>\n",
       "      <td>hershey s chocolate cake with frosting</td>\n",
       "      <td>70</td>\n",
       "      <td>2005-03-22</td>\n",
       "      <td>one night i was craving chocolate cake, but we...</td>\n",
       "      <td>4.892404</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/113914\">h...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49613</th>\n",
       "      <td>the best chocolate cake  really</td>\n",
       "      <td>75</td>\n",
       "      <td>2002-12-22</td>\n",
       "      <td>i made this cake for my little brother's 12th ...</td>\n",
       "      <td>4.891674</td>\n",
       "      <td><a href=\"https://www.food.com/recipe/49613\">ht...</td>\n",
       "      <td><a href=\"https://img.sndimg.com:443/food/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_recommendations(60992, mixed_sim, content_processed, interactions, recipes_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions based on Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = interactions['user_id'].values\n",
    "rids = interactions['recipe_id'].values\n",
    "\n",
    "predictions_mixed = []\n",
    "actual_mixed = []\n",
    "\n",
    "#Make a prediction for each interaction in the interactions df\n",
    "for i in range(len(interactions)):\n",
    "    act, pred = get_one_prediction(mixed_sim, content_processed, interactions, uids[i], rids[i])\n",
    "    predictions_mixed.append(pred)\n",
    "    actual_mixed.append(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mixed = mean_squared_error(predictions_mixed, actual_mixed)**0.5\n",
    "mae_mixed = mean_absolute_error(predictions_mixed, actual_mixed)\n",
    "print(f'RMSE: {rmse_mixed}, MAE: {mae_mixed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['predicted_rating_mixed'] = [item for sublist in predictions_mixed for item in sublist]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rating_dist(round(interactions.predicted_rating_mixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize lambda parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_mix_param(lmbdas, processed, interactions_data, recipes_data):\n",
    "    rmse_mix = []\n",
    "    \n",
    "    interactions_processed = get_interaction_processed(processed, interactions_data)\n",
    "    uid_sample = interactions_processed['user_id'].values\n",
    "    rid_sample = interactions_processed['recipe_id'].values\n",
    "    \n",
    "    for lmbda in lmbdas:\n",
    "        mixed_sim = get_mix_sim_matrix(processed, lmbda, recipes_data)\n",
    "        predictions_mix, actual_mix = [], []\n",
    "        for i in range(len(interactions_processed)):\n",
    "            try:\n",
    "                act, pred = get_results_cos(processed, \n",
    "                                            interactions_processed, \n",
    "                                            recipes_data, \n",
    "                                            rid_sample[i], \n",
    "                                            uid_sample[i], \n",
    "                                            mixed_sim, \n",
    "                                            5)\n",
    "                predictions_mix.append(pred)\n",
    "                actual_mix.append(act)\n",
    "                except:\n",
    "                    next\n",
    "        rmse = mean_squared_error(predictions_mix, actual_mix)**0.5\n",
    "        rmse_mix.append(rmse)\n",
    "    return rmse_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mix_tune = tuning_mix_param(lmbdas,\n",
    "                                 processed_s, \n",
    "                                 interactions_data, \n",
    "                                 recipes_data)\n",
    "rmse_mix_min = min(rmse_mix_tune)\n",
    "rmse_mix_min_idx = rmse_mix_tune.index(rmse_mix_min)\n",
    "lmbda_min = lmbdas[rmse_mix_min_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lmbdas, rmse_mix_tune)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for different mixture models')\n",
    "plt.plot([lmbda_min], [rmse_mix_min], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3. Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
